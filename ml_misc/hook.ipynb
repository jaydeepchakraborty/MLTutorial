{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec6d536-71f5-4b18-9d8f-e80d190f292f",
   "metadata": {},
   "source": [
    "--> torch hook is great way to check the output of any network layer <br>\n",
    "**Pros:** <br>\n",
    "The torch hook can be used during inference. Any network (previously trained) can be loaded and hook ables to debug/print/visualize output during inference/test. <br>\n",
    "**Cons:** <br>\n",
    "hook can not print the intermediate variables in forward method.<br>\n",
    "\n",
    "To get the intermediate value, it has to be encapsulated in another class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f48c39e-cc2a-4e82-ba4f-234f158bb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17d7cd37-76cb-4ba5-ac33-6fe064ea1246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matmul(nn.Module):\n",
    "    def forward(self, **kwargs):\n",
    "        return kwargs['op'] * kwargs['multiplier']\n",
    "\n",
    "class DummyHookNet(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dummy_linear_layer = nn.Sequential(OrderedDict([\n",
    "            ('1_LINEAR_LAYER', nn.Linear(conf['in'], conf['out'])),\n",
    "            ('2_MUL_LAYER', Matmul()),\n",
    "            ('3_RELU_LAYER', nn.LeakyReLU()),\n",
    "            ('4_DROP_LAYER', nn.Dropout(p=conf['drop_out']))\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x, multiplier):\n",
    "        layer_1 = self.dummy_linear_layer._modules['1_LINEAR_LAYER']\n",
    "        layer_1_op = layer_1(x)\n",
    "        \n",
    "        layer_2 = self.dummy_linear_layer._modules['2_MUL_LAYER']\n",
    "        layer_2_op = layer_2(op = layer_1_op, multiplier = multiplier)\n",
    "        \n",
    "        print(\"layer_2\\n\",layer_2_op)\n",
    "        \n",
    "        layer_3 = self.dummy_linear_layer._modules['3_RELU_LAYER']\n",
    "        layer_3_op = layer_3(layer_2_op)\n",
    "        \n",
    "        layer_4 = self.dummy_linear_layer._modules['4_DROP_LAYER']\n",
    "        layer_4_op = layer_4(layer_3_op)\n",
    "        \n",
    "        return layer_3_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f764a54b-5359-4c14-9b42-9fcf57ec31de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_hook():\n",
    "    try:\n",
    "        conf = {\n",
    "            \"in\": 3,\n",
    "            \"out\": 5,\n",
    "            \"drop_out\": 0.1\n",
    "        }\n",
    "        dummy_hook_net = DummyHookNet(conf)\n",
    " \n",
    "        dummy_handle_1 = dummy_hook_net.dummy_linear_layer._modules['1_LINEAR_LAYER'].register_forward_hook(\n",
    "            lambda m,\n",
    "            input,\n",
    "            output: print(\"layer_1\\n\",output)\n",
    "        )\n",
    "    \n",
    "        dummy_handle_2 = dummy_hook_net.dummy_linear_layer._modules['2_MUL_LAYER'].register_forward_hook(\n",
    "            lambda m,\n",
    "            input,\n",
    "            output: print(\"layer_2\\n\",output)\n",
    "        )\n",
    "        \n",
    "        inp = torch.rand(2, 3)\n",
    "        oup = dummy_hook_net(inp, 5)\n",
    "        # print(oup)\n",
    "        \n",
    "        dummy_handle_1.remove()\n",
    "        dummy_handle_2.remove()\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "437f0b58-5cee-4fa4-b23d-00546b8f3401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_1\n",
      " tensor([[ 0.3367, -0.0996,  0.7458,  0.0084,  0.0412],\n",
      "        [ 0.3578, -0.1920,  0.6517, -0.1853,  0.1640]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "layer_2\n",
      " tensor([[ 1.6837, -0.4979,  3.7288,  0.0421,  0.2061],\n",
      "        [ 1.7888, -0.9600,  3.2583, -0.9267,  0.8202]], grad_fn=<MulBackward0>)\n",
      "layer_2\n",
      " tensor([[ 1.6837, -0.4979,  3.7288,  0.0421,  0.2061],\n",
      "        [ 1.7888, -0.9600,  3.2583, -0.9267,  0.8202]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "invoke_hook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796476d6-c5cb-4507-9878-60f7bec27a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Resources\n",
    "1) https://dev.to/jankrepl/forward-hooks-in-pytorch-4eeh\n",
    "2) https://github.com/elliotwaite/pytorch-hooks-tutorial\n",
    "3) https://discuss.pytorch.org/t/how-can-l-load-my-best-model-as-a-feature-extractor-evaluator/17254/20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
