{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad24c42-a31f-4226-9119-56ca09631f37",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Gaussian Naive Bayes](#gaussian_naive_bayes)\n",
    "* [Data load](#data_load)\n",
    "* [Math Explanation](#math_expl)\n",
    "* [SciKit GaussianNB](#sci_gnb)\n",
    "* [Questions](#questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f1244e-1e69-4059-bff2-de0b77aeb6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import traceback\n",
    "import math\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2231646c-616e-4b47-88c8-97c97988ab43",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes <a class=\"anchor\" id=\"gaussian_naive_bayes\"></a>\n",
    "$\n",
    "\\begin{align}\n",
    "& \\hat{y} = \\underset{k \\in {1, .., K}}{\\mathrm{arg\\,max}} P(y_k) \\prod_{i=1}^{d} p(x_i | y_k) \\\\\n",
    "& P(x_{i}\\mid y_{k}) = \\frac{1}{\\sigma_{y_{k}}\\sqrt{2\\pi}} \n",
    "  \\exp\\left( -\\frac{1}{2}\\left(\\frac{x_{i}-\\mu_{y_{k}}}{\\sigma_{y_{k}}}\\right)^{\\!2}\\,\\right) \\\\\n",
    "& log(P(x_{i}\\mid y_{k})) = -0.5*log(2\\pi\\sigma_{y_{k}}^2) - 0.5*\\left(\\frac{x_{i}-\\mu_{y_{k}}}{\\sigma_{y_{k}}}\\right)^{\\!2}\n",
    "\\end{align}\n",
    "$\n",
    "<br><br>\n",
    "--> <b>Assumptions:</b> <br>\n",
    "1) features are independent within each class (no co-relation). <br>\n",
    "2) (Gaussian) Naive Bayes assumes that each class follow a Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1668f98a-fcd6-4677-b3d4-9e1617213646",
   "metadata": {},
   "source": [
    "## Data load <a class=\"anchor\" id=\"data_load\"></a>\n",
    "https://www.kaggle.com/datasets/whenamancodes/fraud-detection <br>\n",
    "-- selected three features ['V1', 'V4', 'V7'] <br>\n",
    "-- target is 'Class' ~ Fraudulent (1) or Genuine (0) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87fdf48f-122a-4666-9d87-562a0167c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf():\n",
    "    try:\n",
    "        conf = {\n",
    "            \"data_fl_path\": \"../DataSets/creditcard.csv\"\n",
    "        }       \n",
    "        return conf\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6641bf6-6bf7-4934-8305-6a85c2a50728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(conf):\n",
    "    try:\n",
    "        df = pd.read_csv(conf[\"data_fl_path\"])\n",
    "        df = df[['V1', 'V4', 'V7', 'Class']]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baa0c391-b09f-4e8d-93ed-5c727f735924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of  Fraudulent (1) or Genuine (0) in dataset'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V4</th>\n",
       "      <th>V7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V4        V7  Class\n",
       "0 -1.359807  1.378155  0.239599      0\n",
       "1  1.191857  0.448154 -0.078803      0\n",
       "2 -1.358354  0.379780  0.791461      0\n",
       "3 -0.966272 -0.863291  0.237609      0\n",
       "4 -1.158233  0.403034  0.592941      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def data_explor():\n",
    "    try:\n",
    "        conf = get_conf()\n",
    "        df = load_data(conf)\n",
    "        display(\"Number of  Fraudulent (1) or Genuine (0) in dataset\")\n",
    "        display(df['Class'].value_counts())\n",
    "        display(df.head())\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        \n",
    "data_df = data_explor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83078d8f-9ec5-4d8b-82dc-721ba79e0893",
   "metadata": {},
   "source": [
    "## Math Explanation <a class=\"anchor\" id=\"math_expl\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94d7d37f-6f9b-4415-8e80-a06718b544bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Distribution Parameter of class Fraudulent (1)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean- mu</th>\n",
       "      <th>Std.Dev - sigma</th>\n",
       "      <th>Var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>-4.771948</td>\n",
       "      <td>6.783687</td>\n",
       "      <td>46.018406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>4.542029</td>\n",
       "      <td>2.873318</td>\n",
       "      <td>8.255955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>-5.568731</td>\n",
       "      <td>7.206773</td>\n",
       "      <td>51.937575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean- mu  Std.Dev - sigma        Var\n",
       "V1 -4.771948         6.783687  46.018406\n",
       "V4  4.542029         2.873318   8.255955\n",
       "V7 -5.568731         7.206773  51.937575"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Distribution Parameter of class Genuine (0)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean - mu</th>\n",
       "      <th>Std.Dev - sigma</th>\n",
       "      <th>Var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>0.008258</td>\n",
       "      <td>1.929814</td>\n",
       "      <td>3.724182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>-0.007860</td>\n",
       "      <td>1.399333</td>\n",
       "      <td>1.958134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>0.009637</td>\n",
       "      <td>1.178812</td>\n",
       "      <td>1.389598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean - mu  Std.Dev - sigma       Var\n",
       "V1   0.008258         1.929814  3.724182\n",
       "V4  -0.007860         1.399333  1.958134\n",
       "V7   0.009637         1.178812  1.389598"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "From our training data\n",
    "'''\n",
    "stats_1=pd.DataFrame()\n",
    "df_1 = data_df.loc[data_df['Class'] == 1]\n",
    "stats_1[\"mean- mu\"]=df_1[['V1', 'V4', 'V7']].mean()\n",
    "stats_1[\"Std.Dev - sigma\"]=df_1[['V1', 'V4', 'V7']].std()\n",
    "stats_1[\"Var\"]=df_1[['V1', 'V4', 'V7']].var()\n",
    "\n",
    "\n",
    "stats_0=pd.DataFrame()\n",
    "df_0 = data_df.loc[data_df['Class'] == 0]\n",
    "stats_0[\"mean - mu\"]=df_0[['V1', 'V4', 'V7']].mean()\n",
    "stats_0[\"Std.Dev - sigma\"]=df_0[['V1', 'V4', 'V7']].std()\n",
    "stats_0[\"Var\"]=df_0[['V1', 'V4', 'V7']].var()\n",
    "\n",
    "display(\"Distribution Parameter of class Fraudulent (1)\")\n",
    "display(stats_1)\n",
    "\n",
    "display(\"Distribution Parameter of class Genuine (0)\")\n",
    "display(stats_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf70137-3211-4a6a-a2a4-e09fcab9d78d",
   "metadata": {},
   "source": [
    "--> <b>let's take a TEST instance</b> <br>\n",
    "\n",
    "<table style=\"float:left\">\n",
    "    <tr>\n",
    "        <td>V1</td> <td>V4</td> <td>V7</td> <td>CLASS</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1.191857</td> <td>0.448154</td> <td>-0.078803</td> <td>?</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>-3.0435406239976</td> <td>2.2886436183814</td> <td>0.325574266158614</td> <td>?</td>\n",
    "    </tr>   \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1a4d85-e1f4-4583-a480-ad5742789303",
   "metadata": {},
   "source": [
    "So, We have calculate the below <br><br>\n",
    "For Fraudulent (1) <br>\n",
    "$\n",
    "\\begin{align}\n",
    "& P(y = 1|X) = P(y = 1) \\prod_{i=1}^{d} p(x_i | y = 1) \\\\\n",
    "& = P(y = 1) p(x = V1 | y = 1) p(x = V4 | y = 1) p(x = V7 | y = 1) \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "For Genuine (0) <br>\n",
    "$\n",
    "\\begin{align}\n",
    "& P(y = 0|X) = P(y = 0) \\prod_{i=1}^{d} p(x_i | y = 0) \\\\\n",
    "& = P(y = 0) p(x = V1 | y = 0) p(x = V4 | y = 0) p(x = V7 | y = 0) \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "After this, we have to compare $P(y = 1|X)$ and $P(y = 0|X)$. Which ever is bigger, we will assign the test instance to that Class (0/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a96b0a-6476-43ec-a426-16461de774de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(P = y1):- 0.001727485630620034'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'(P = y0):- 0.9982725143693799'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "First, the prior calculation,\n",
    "'''\n",
    "P_y1 = len(data_df.loc[data_df['Class'] == 1]) / len(data_df)\n",
    "P_y0 = len(data_df.loc[data_df['Class'] == 0]) / len(data_df)\n",
    "\n",
    "display(f'(P = y1):- {P_y1}')\n",
    "display(f'(P = y0):- {P_y0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ae8618-37d4-4d38-81b7-f7a471b06ab3",
   "metadata": {},
   "source": [
    "***\n",
    "<b>TestCase-1</b> <br>\n",
    "V1: 1.191857 V4: 0.448154 V7: -0.078803 Class: ? \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd35721-9c46-4261-8b13-891e99f58863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P_y1:- 0.001727485630620034, P_y1_xv1:- -3.2199021381220847, P_y1_xv4:- -2.9894193871916257, P_y1_xv7:- -3.1841091710093594'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'P_y1_xv1v4v7:- -15.754519016700355'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "now calculate the likelihood of y1 ~ Fraudulent (1)\n",
    "'''\n",
    "\n",
    "def pdf(x, mu=0.0, sigma=1.0):\n",
    "    comp_1 = float(1 / (sigma * math.sqrt(2.0*math.pi)))\n",
    "    \n",
    "    comp_2_1 = math.pow(float((x - mu) / sigma), 2)\n",
    "    comp_2_2 = (-1/2.0)*comp_2_1\n",
    "    comp_2 = math.exp(comp_2_2)\n",
    "    \n",
    "    comp = comp_1 * comp_2\n",
    "    \n",
    "    return comp\n",
    "\n",
    "def pdf_log(x, mu=0.0, sigma=1.0):\n",
    "    comp_1 = -0.5*math.log((2.0*math.pi*math.pow(sigma,2)))\n",
    "    \n",
    "    comp_2 = -0.5*math.pow(float((x - mu) / sigma), 2)\n",
    "    \n",
    "    comp = comp_1 + comp_2\n",
    "    \n",
    "    return comp\n",
    "\n",
    "x_y1_v1 = 1.191857\n",
    "mu_y1_v1 = -4.771948\n",
    "sigma_y1_v1 = 6.783687\n",
    "P_y1_xv1 = pdf_log(x_y1_v1, mu=mu_y1_v1, sigma=sigma_y1_v1)\n",
    "\n",
    "x_y1_v4 = 0.448154\n",
    "mu_y1_v4 = 4.542029\n",
    "sigma_y1_v4 = 2.873318\n",
    "P_y1_xv4 = pdf_log(x_y1_v4, mu=mu_y1_v4, sigma=sigma_y1_v4)\n",
    "\n",
    "x_y1_v7 = -0.078803\n",
    "mu_y1_v7 = -5.568731\n",
    "sigma_y1_v7 = 7.206773\n",
    "P_y1_xv7 = pdf_log(x_y1_v7, mu=mu_y1_v7, sigma=sigma_y1_v7)\n",
    "\n",
    "# pdf\n",
    "# P_y1_xv1v4v7 = P_y1 * P_y1_xv1 * P_y1_xv4 * P_y1_xv7\n",
    "# log pdf\n",
    "P_y1_xv1v4v7 = math.log(P_y1) + P_y1_xv1 + P_y1_xv4 + P_y1_xv7\n",
    "\n",
    "display(f\"P_y1:- {P_y1}, P_y1_xv1:- {P_y1_xv1}, P_y1_xv4:- {P_y1_xv4}, P_y1_xv7:- {P_y1_xv7}\")\n",
    "display(f\"P_y1_xv1v4v7:- {P_y1_xv1v4v7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "481e7c02-2c65-4c38-8daf-bfd6f6b45edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P_y0:- 0.9982725143693799, P_y0_xv1:- -1.7644446104514482, P_y0_xv4:- -1.3080329663381352, P_y0_xv7:- -1.0862600366231299'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'P_y0_xv1v4v7:- -4.160466592867256'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "now calculate the likelihood of y0 ~ Genuine (0)\n",
    "'''\n",
    "\n",
    "def pdf(x, mu=0.0, sigma=1.0):\n",
    "    comp_1 = float(1 / (sigma * math.sqrt(2.0*math.pi)))\n",
    "    \n",
    "    comp_2_1 = math.pow(float((x - mu) / sigma), 2)\n",
    "    comp_2_2 = (-1/2.0)*comp_2_1\n",
    "    comp_2 = math.exp(comp_2_2)\n",
    "    \n",
    "    comp = comp_1 * comp_2\n",
    "    \n",
    "    return comp\n",
    "\n",
    "def pdf_log(x, mu=0.0, sigma=1.0):\n",
    "    comp_1 = -0.5*math.log((2.0*math.pi*math.pow(sigma,2)))\n",
    "    \n",
    "    comp_2 = -0.5*math.pow(float((x - mu) / sigma), 2)\n",
    "    \n",
    "    comp = comp_1 + comp_2\n",
    "    \n",
    "    return comp\n",
    "\n",
    "x_y0_v1 = 1.191857\n",
    "mu_y0_v1 = 0.008258\n",
    "sigma_y0_v1 = 1.929814\n",
    "P_y0_xv1 = pdf_log(x_y0_v1, mu=mu_y0_v1, sigma=sigma_y0_v1)\n",
    "\n",
    "x_y0_v4 = 0.448154\n",
    "mu_y0_v4 = -0.007860\n",
    "sigma_y0_v4 = 1.399333\n",
    "P_y0_xv4 = pdf_log(x_y0_v4, mu=mu_y0_v4, sigma=sigma_y0_v4)\n",
    "\n",
    "x_y0_v7 = -0.078803\n",
    "mu_y0_v7 = 0.009637\n",
    "sigma_y0_v7 = 1.178812\n",
    "P_y0_xv7 = pdf_log(x_y0_v7, mu=mu_y0_v7, sigma=sigma_y0_v7)\n",
    "\n",
    "# pdf\n",
    "# P_y0_xv1v4v7 = P_y0 * P_y0_xv1 * P_y0_xv4 * P_y0_xv7\n",
    "# log pdf\n",
    "P_y0_xv1v4v7 = math.log(P_y0) + P_y0_xv1 + P_y0_xv4 + P_y0_xv7\n",
    "\n",
    "display(f\"P_y0:- {P_y0}, P_y0_xv1:- {P_y0_xv1}, P_y0_xv4:- {P_y0_xv4}, P_y0_xv7:- {P_y0_xv7}\")\n",
    "display(f\"P_y0_xv1v4v7:- {P_y0_xv1v4v7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d84d6ab3-0e4b-433b-89ed-1b5ffe083d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data point is Genuine (0)\n",
      "P_y0_xv1v4v7:- -4.160466592867256, P_y1_xv1v4v7:- -15.754519016700355\n"
     ]
    }
   ],
   "source": [
    "if P_y0_xv1v4v7 > P_y1_xv1v4v7:\n",
    "    print(\"test data point is Genuine (0)\")\n",
    "    print(f\"P_y0_xv1v4v7:- {P_y0_xv1v4v7}, P_y1_xv1v4v7:- {P_y1_xv1v4v7}\")\n",
    "else:\n",
    "    print(\"test data point is Fraudulent (1)\")\n",
    "    print(f\"P_y0_xv1v4v7:- {P_y0_xv1v4v7}, P_y1_xv1v4v7:- {P_y1_xv1v4v7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19bf77a-bf74-4f82-84c0-2e53ceb769ee",
   "metadata": {},
   "source": [
    "## SciKit GaussianNB <a class=\"anchor\" id=\"sci_gnb\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad57bfd-688d-423b-a363-46a439e6fa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 3) (284807,)\n",
      "Sklearn values:\n",
      "Mean is [[ 0.00825774 -0.00785987  0.00963655]\n",
      " [-4.77194844  4.5420291  -5.56873108]]\n",
      "Variance is [[ 3.72416918  1.95812662  1.3895933 ]\n",
      " [45.92487267  8.23917414 51.83201046]]\n"
     ]
    }
   ],
   "source": [
    "X_train = data_df[['V1', 'V4', 'V7']]\n",
    "y_train = data_df.Class\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# instantiate the model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# fit the model\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "print('Sklearn values:')\n",
    "print('Mean is',gnb.theta_)\n",
    "print('Variance is',gnb.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c6e2334-a80a-4c01-9dd2-db5896230379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.16046253 -15.75491257]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "arr_test = [[1.191857, 0.448154, -0.078803]]\n",
    "X_test=pd.DataFrame(arr_test, columns=['V1', 'V4', 'V7'])\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(gnb._joint_log_likelihood(X_test))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ccb4fe-aad2-4707-b3d3-378b9b9add65",
   "metadata": {},
   "source": [
    "***\n",
    "<b>TestCase-2</b> <br>\n",
    "V1: -3.0435406239976 V2:2.2886436183814 V3: 0.325574266158614 Class: ?  \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5a46af4-90e9-4d65-9c28-efcbf828b073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P_y1:- 0.001727485630620034, P_y1_xv1:- -2.8659179554189693, P_y1_xv4:- -2.281926131908617, P_y1_xv7:- -3.22842703665569'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'P_y1_xv1v4v7:- -14.737359444360562'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "now calculate the likelihood of y1 ~ Fraudulent (1)\n",
    "'''\n",
    "\n",
    "def pdf(x, mu=0.0, sigma=1.0):\n",
    "    comp_1 = float(1 / (sigma * math.sqrt(2.0*math.pi)))\n",
    "    \n",
    "    comp_2_1 = math.pow(float((x - mu) / sigma), 2)\n",
    "    comp_2_2 = (-1/2.0)*comp_2_1\n",
    "    comp_2 = math.exp(comp_2_2)\n",
    "    \n",
    "    comp = comp_1 * comp_2\n",
    "    \n",
    "    return comp\n",
    "\n",
    "def pdf_log(x, mu=0.0, sigma=1.0):\n",
    "    comp_1 = -0.5*math.log((2.0*math.pi*math.pow(sigma,2)))\n",
    "    \n",
    "    comp_2 = -0.5*math.pow(float((x - mu) / sigma), 2)\n",
    "    \n",
    "    comp = comp_1 + comp_2\n",
    "    \n",
    "    return comp\n",
    "\n",
    "x_y1_v1 = -3.0435406239976\n",
    "mu_y1_v1 = -4.771948\n",
    "sigma_y1_v1 = 6.783687\n",
    "P_y1_xv1 = pdf_log(x_y1_v1, mu=mu_y1_v1, sigma=sigma_y1_v1)\n",
    "\n",
    "x_y1_v4 = 2.2886436183814\n",
    "mu_y1_v4 = 4.542029\n",
    "sigma_y1_v4 = 2.873318\n",
    "P_y1_xv4 = pdf_log(x_y1_v4, mu=mu_y1_v4, sigma=sigma_y1_v4)\n",
    "\n",
    "x_y1_v7 = 0.325574266158614\n",
    "mu_y1_v7 = -5.568731\n",
    "sigma_y1_v7 = 7.206773\n",
    "P_y1_xv7 = pdf_log(x_y1_v7, mu=mu_y1_v7, sigma=sigma_y1_v7)\n",
    "\n",
    "# pdf\n",
    "# P_y1_xv1v4v7 = P_y1 * P_y1_xv1 * P_y1_xv4 * P_y1_xv7\n",
    "# log pdf\n",
    "P_y1_xv1v4v7 = math.log(P_y1) + P_y1_xv1 + P_y1_xv4 + P_y1_xv7\n",
    "\n",
    "display(f\"P_y1:- {P_y1}, P_y1_xv1:- {P_y1_xv1}, P_y1_xv4:- {P_y1_xv4}, P_y1_xv7:- {P_y1_xv7}\")\n",
    "display(f\"P_y1_xv1v4v7:- {P_y1_xv1v4v7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a230761d-d58c-442d-b139-b16e0fc01dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P_y0:- 0.9982725143693799, P_y0_xv1:- -2.826767570250749, P_y0_xv4:- -2.6016071266066216, P_y0_xv7:- -1.11936124299125'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'P_y0_xv1v4v7:- -6.549464919303164'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "now calculate the likelihood of y0 ~ Genuine (0)\n",
    "'''\n",
    "\n",
    "def pdf(x, mu=0.0, sigma=1.0):\n",
    "    comp_1 = float(1 / (sigma * math.sqrt(2.0*math.pi)))\n",
    "    \n",
    "    comp_2_1 = math.pow(float((x - mu) / sigma), 2)\n",
    "    comp_2_2 = (-1/2.0)*comp_2_1\n",
    "    comp_2 = math.exp(comp_2_2)\n",
    "    \n",
    "    comp = comp_1 * comp_2\n",
    "    \n",
    "    return comp\n",
    "\n",
    "def pdf_log(x, mu=0.0, sigma=1.0):\n",
    "    comp_1 = -0.5*math.log((2.0*math.pi*math.pow(sigma,2)))\n",
    "    \n",
    "    comp_2 = -0.5*math.pow(float((x - mu) / sigma), 2)\n",
    "    \n",
    "    comp = comp_1 + comp_2\n",
    "    \n",
    "    return comp\n",
    "\n",
    "x_y0_v1 = -3.0435406239976\n",
    "mu_y0_v1 = 0.008258\n",
    "sigma_y0_v1 = 1.929814\n",
    "P_y0_xv1 = pdf_log(x_y0_v1, mu=mu_y0_v1, sigma=sigma_y0_v1)\n",
    "\n",
    "x_y0_v4 = 2.2886436183814\n",
    "mu_y0_v4 = -0.007860\n",
    "sigma_y0_v4 = 1.399333\n",
    "P_y0_xv4 = pdf_log(x_y0_v4, mu=mu_y0_v4, sigma=sigma_y0_v4)\n",
    "\n",
    "x_y0_v7 = 0.325574266158614\n",
    "mu_y0_v7 = 0.009637\n",
    "sigma_y0_v7 = 1.178812\n",
    "P_y0_xv7 = pdf_log(x_y0_v7, mu=mu_y0_v7, sigma=sigma_y0_v7)\n",
    "\n",
    "# pdf\n",
    "# P_y0_xv1v4v7 = P_y0 * P_y0_xv1 * P_y0_xv4 * P_y0_xv7\n",
    "# log pdf\n",
    "P_y0_xv1v4v7 = math.log(P_y0) + P_y0_xv1 + P_y0_xv4 + P_y0_xv7\n",
    "\n",
    "display(f\"P_y0:- {P_y0}, P_y0_xv1:- {P_y0_xv1}, P_y0_xv4:- {P_y0_xv4}, P_y0_xv7:- {P_y0_xv7}\")\n",
    "display(f\"P_y0_xv1v4v7:- {P_y0_xv1v4v7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "49cd0e1c-0072-47fd-846e-bbd77a71c602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data point is Genuine (0)\n",
      "P_y0_xv1v4v7:- -6.549464919303164, P_y1_xv1v4v7:- -14.737359444360562\n"
     ]
    }
   ],
   "source": [
    "if P_y0_xv1v4v7 > P_y1_xv1v4v7:\n",
    "    print(\"test data point is Genuine (0)\")\n",
    "    print(f\"P_y0_xv1v4v7:- {P_y0_xv1v4v7}, P_y1_xv1v4v7:- {P_y1_xv1v4v7}\")\n",
    "else:\n",
    "    print(\"test data point is Fraudulent (1)\")\n",
    "    print(f\"P_y0_xv1v4v7:- {P_y0_xv1v4v7}, P_y1_xv1v4v7:- {P_y1_xv1v4v7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda74833-b82c-451b-ab8f-678b4c9254fe",
   "metadata": {},
   "source": [
    "## SciKit GaussianNB <a class=\"anchor\" id=\"sci_gnb\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8df892b7-edf6-4176-bad1-7b3182151c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -6.54946846 -14.73568115]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "arr_test = [[-3.0435406239976, 2.2886436183814, 0.325574266158614]]\n",
    "X_test=pd.DataFrame(arr_test, columns=['V1', 'V4', 'V7'])\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(gnb._joint_log_likelihood(X_test))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a930e-ade5-48ea-982a-f457bb8cf733",
   "metadata": {},
   "source": [
    "## Resources\n",
    "1) https://www.kaggle.com/code/prashant111/naive-bayes-classifier-in-python\n",
    "2) https://www.youtube.com/watch?v=IvTCdrx1SHQ\n",
    "3) https://www.kaggle.com/code/ryanluoli2/a-complete-guide-to-naive-bayes-classifiers\n",
    "4) https://towardsdatascience.com/how-i-was-using-naive-bayes-incorrectly-till-now-part-1-4ed2a7e2212b\n",
    "5) https://towardsdatascience.com/how-i-was-using-naive-bayes-incorrectly-till-now-part-2-d31feff72483 \n",
    "6) http://blog.axelmendoza.fr/naive-bayes/alcohol/pytorch/eda/from-scratch/2020/09/17/Naive-Bayes-Classifier.html\n",
    "7) https://pub.towardsai.net/gaussian-naive-bayes-explained-and-hands-on-with-scikit-learn-4183b8cb0e4c\n",
    "8) https://www.youtube.com/watch?v=3I8oX3OUL6I\n",
    "9) https://www.youtube.com/watch?v=Po6lsacF5pw\n",
    "10) https://medium.com/@christopherfielding/na%C3%AFve-bayes-classification-for-discrete-and-continuous-variables-cb1103155488\n",
    "11) https://www.youtube.com/watch?v=IvTCdrx1SHQ\n",
    "12) https://towardsdatascience.com/why-how-to-use-the-naive-bayes-algorithms-in-a-regulated-industry-with-sklearn-python-code-dbd8304ab2cf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500b028-ac86-4be5-a68d-ee728a6b75c5",
   "metadata": {},
   "source": [
    "## QUESTIONS <a class=\"anchor\" id=\"questions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b99b66-8cee-4e48-bb6b-b687e0156af2",
   "metadata": {},
   "source": [
    "1) <b>Why gaussian distribution?</b> <br>\n",
    "\n",
    "Naive Bayes can be extended to real-valued attributes, most commonly by assuming a Gaussian distribution. <br>\n",
    "\n",
    "This extension of naive Bayes is called Gaussian Naive Bayes. Other functions can be used to estimate the distribution of the data, \n",
    "but the Gaussian (or Normal distribution) is the easiest to work with because you only need to estimate the mean and the standard deviation from your training data.\n",
    "\n",
    "It is better to use whether features are normally distributed or not. <br>\n",
    "1) plot probability distribution - sns.kdeplot/histogram <br>\n",
    "2) Q-Q plot <br>\n",
    "3) Shapiro–Wilk test <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1885fa-31ad-4730-b293-540f114c6c42",
   "metadata": {},
   "source": [
    "2) <b>Features Independence?</b> <br>\n",
    "\n",
    "The assumption of independent features. In practice, it is almost impossible that the model will get a set of predictors that are entirely independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f99a017-ba0a-43e7-9e63-7561d14bf3d6",
   "metadata": {},
   "source": [
    "3) <b>Zero Probability?</b> <br>\n",
    "\n",
    "If there is no training tuple of a particular class, this causes zero posterior probability. In this case, the model is unable to make predictions. \n",
    "This problem is known as Zero Probability/Frequency Problem. <br>\n",
    "\n",
    "$P(cloudy | rain)$\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "& P(cloudy \\mid rain)  \\\\\n",
    "&  = \\frac{(no of points where day is cloudy and rain is yes)}{(no of points where day is cloudy and rain is yes)} \\\\ \n",
    "&  = \\frac{(no of points where day is cloudy and rain is yes + \\alpha)}{(no of points where day is cloudy and rain is yes + c\\alpha)} \\\\ \n",
    "\\end{align}\n",
    "$\n",
    "<br>\n",
    "$\\alpha$ is hyperparameter <br>\n",
    "$c$ is number of classes <br>\n",
    "$\\alpha$ is small -> overfitting <br>\n",
    "$\\alpha$ is big -> underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb66b9-b8c9-4039-8afa-d85c32d479cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
