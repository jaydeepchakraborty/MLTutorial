{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN-Attention-PAD((seq) -> 1).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO+R2wIU9aNTk+zx1fZyDoE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install -U torch==1.10.0 torchtext==0.11.0\n","\n","# Reload environment\n","exit()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lK6tS1J8m71Z","executionInfo":{"status":"ok","timestamp":1651167768359,"user_tz":300,"elapsed":113616,"user":{"displayName":"Jaydeep Chakraborty","userId":"04716741579620071152"}},"outputId":"a34b01c3-b839-46dc-9dcc-745453103c38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 14 kB/s \n","\u001b[?25hCollecting torchtext==0.9.0\n","  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 33.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (4.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (4.64.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2.10)\n","Installing collected packages: torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.12.0\n","    Uninstalling torchtext-0.12.0:\n","      Successfully uninstalled torchtext-0.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.8.0 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.8.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.8.0 torchtext-0.9.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzNsZnK7UWyr"},"outputs":[],"source":["import random\n","import re\n","import pandas as pd\n","import spacy\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torchtext.legacy import data"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","g_path = \"/content/drive/My Drive/pytorch/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UdcYIgPIUald","executionInfo":{"status":"ok","timestamp":1651168071747,"user_tz":300,"elapsed":14166,"user":{"displayName":"Jaydeep Chakraborty","userId":"04716741579620071152"}},"outputId":"f483a17e-f5b1-4a4f-e068-952fb786d323"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data_fl = 'data/IMDB_review_sentiment_small.csv'"],"metadata":{"id":"FZrVtJ2xhaSJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#reproducing the same result\n","SEED = 2021\n","torch.manual_seed(SEED)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRHqfw6sVSZZ","executionInfo":{"status":"ok","timestamp":1651168103856,"user_tz":300,"elapsed":151,"user":{"displayName":"Jaydeep Chakraborty","userId":"04716741579620071152"}},"outputId":"be0beaed-6ef4-472f-9e0d-c4313566136b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fdc52ed3a30>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["spacy_en = spacy.load('en')\n","def clean_data(texts):\n","    cleaned_text = []\n","    for text in texts:\n","        # remove break\n","        text = text.replace('br', '')\n","        # remove punctuation\n","        text = re.sub('[^a-zA-Z0-9]', ' ', text)\n","        # remove multiple spaces\n","        text = re.sub(r' +', ' ', text)\n","        # remove newline\n","        text = re.sub(r'\\n', ' ', text)\n","        # strip the text\n","        text = text.strip()\n","        # lower the text\n","        text = text.lower()\n","\n","        if text != '':\n","          cleaned_text.append(text)\n","    return cleaned_text\n","\n","def tokenizer(text):\n","    return [tok.text for tok in spacy_en.tokenizer(text)]\n","\n","TEXT = data.Field(preprocessing=clean_data,tokenize=tokenizer,batch_first=True,include_lengths=True)\n","LABEL = data.LabelField(dtype = torch.float,batch_first=True)\n","fields = [('text',TEXT),('label', LABEL)]"],"metadata":{"id":"47Us8mAaVWFm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#loading the entire data\n","def load_data():\n","  imdb_data = data.TabularDataset(path = g_path+data_fl,format = 'csv', fields = fields, skip_header = True)\n","  return imdb_data\n","\n","imdb_data = load_data() \n","print(vars(imdb_data.examples[0]))\n","print(imdb_data.examples[0].text, imdb_data.examples[0].label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5qTpaDVpVZQu","executionInfo":{"status":"ok","timestamp":1651168110624,"user_tz":300,"elapsed":794,"user":{"displayName":"Jaydeep Chakraborty","userId":"04716741579620071152"}},"outputId":"b5fed052-1c94-4492-91b2-1616f64c5c87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'text': ['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'oz', 'episode', 'you', 'll', 'be', 'hooked', 'they', 'are', 'right', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'utality', 'and', 'unflinching', 'scenes', 'of', 'violence', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go', 'trust', 'me', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', 'this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', 'sex', 'or', 'violence', 'its', 'is', 'hardcore', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'penitentary', 'it', 'focuses', 'mainly', 'on', 'emerald', 'city', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', 'em', 'city', 'is', 'home', 'to', 'many', 'aryans', 'muslims', 'gangstas', 'latinos', 'christians', 'italians', 'irish', 'and', 'more', 'so', 'scuffles', 'death', 'stares', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'would', 'n t', 'dare', 'forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', 'forget', 'charm', 'forget', 'romance', 'oz', 'does', 'n t', 'mess', 'around', 'the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', 'i', 'could', 'n t', 'say', 'i', 'was', 'ready', 'for', 'it', 'but', 'as', 'i', 'watched', 'more', 'i', 'developed', 'a', 'taste', 'for', 'oz', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', 'not', 'just', 'violence', 'but', 'injustice', 'crooked', 'guards', 'who', 'll', 'be', 'sold', 'out', 'for', 'a', 'nickel', 'inmates', 'who', 'll', 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', 'well', 'mannered', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', 'watching', 'oz', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', 'thats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side'], 'label': '1'}\n","['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'oz', 'episode', 'you', 'll', 'be', 'hooked', 'they', 'are', 'right', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'utality', 'and', 'unflinching', 'scenes', 'of', 'violence', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go', 'trust', 'me', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', 'this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', 'sex', 'or', 'violence', 'its', 'is', 'hardcore', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'penitentary', 'it', 'focuses', 'mainly', 'on', 'emerald', 'city', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', 'em', 'city', 'is', 'home', 'to', 'many', 'aryans', 'muslims', 'gangstas', 'latinos', 'christians', 'italians', 'irish', 'and', 'more', 'so', 'scuffles', 'death', 'stares', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'would', 'n t', 'dare', 'forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', 'forget', 'charm', 'forget', 'romance', 'oz', 'does', 'n t', 'mess', 'around', 'the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', 'i', 'could', 'n t', 'say', 'i', 'was', 'ready', 'for', 'it', 'but', 'as', 'i', 'watched', 'more', 'i', 'developed', 'a', 'taste', 'for', 'oz', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', 'not', 'just', 'violence', 'but', 'injustice', 'crooked', 'guards', 'who', 'll', 'be', 'sold', 'out', 'for', 'a', 'nickel', 'inmates', 'who', 'll', 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', 'well', 'mannered', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', 'watching', 'oz', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', 'thats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side'] 1\n"]}]},{"cell_type":"code","source":["#splitting the data into training and validation dataset\n","def split_data(imdb_data):\n","  train_data, valid_data = imdb_data.split(split_ratio=0.7, random_state = random.seed(SEED))\n","  return train_data, valid_data\n","\n","train_data, valid_data = split_data(imdb_data)"],"metadata":{"id":"r42POVJ6fwT1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#generate vocabulary\n","TEXT.build_vocab(train_data,min_freq=3,vectors = \"glove.6B.100d\")  \n","LABEL.build_vocab(train_data)\n","\n","#No. of unique tokens in text\n","print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n","#No. of unique tokens in label\n","print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xNwDnzrGkea5","executionInfo":{"status":"ok","timestamp":1651168321153,"user_tz":300,"elapsed":205814,"user":{"displayName":"Jaydeep Chakraborty","userId":"04716741579620071152"}},"outputId":"cfd5ffac-5b60-4a40-d3ef-ae05df1f910d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[".vector_cache/glove.6B.zip: 862MB [02:40, 5.36MB/s]                           \n","100%|█████████▉| 399999/400000 [00:16<00:00, 24099.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Size of TEXT vocabulary: 466\n","Size of LABEL vocabulary: 2\n"]}]},{"cell_type":"code","source":["#preparing batches for training the model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n","\n","#set batch size\n","BATCH_SIZE = 5\n","\n","#Load an iterator\n","train_iterator, valid_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data), \n","    batch_size = BATCH_SIZE,\n","    sort_key = lambda x: len(x.text),\n","    sort_within_batch=True,\n","    device = device)"],"metadata":{"id":"ApKB9FJ7-IoC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Attention(nn.Module):\n","\n","  def __init__(self, feature_dim, batch_first, **kwargs):\n","    #Constructor\n","    super(Attention, self).__init__(**kwargs)\n","\n","    #variables\n","    self.batch_first = batch_first\n","\n","    #attention parameters (will be learned via back propagation)\n","    self.W = nn.Parameter(torch.FloatTensor(feature_dim, feature_dim), requires_grad=True)\n","    nn.init.kaiming_uniform_(self.W.data)\n","\n","    self.u = nn.Parameter(torch.FloatTensor(feature_dim,1), requires_grad=True)\n","    nn.init.kaiming_uniform_(self.u.data)\n","\n","\n","  def forward(self, x, x_len, mask=None):\n","    \n","    '''\n","      x is the hidden states (output) from lstm layer\n","      x_len contains information for leangth of each row (sentence) in the batch\n","    '''\n","\n","    '''\n","    get the dimension information based on lstm batch_first logic\n","    '''\n","    if self.batch_first:\n","      batch_size, max_len = x.size()[:2]\n","    else:\n","      max_len, batch_size = x.size()[:2]\n","\n","\n","    '''\n","    x ~ [batch_size, seq_len, feature_dim] ~ feature_dim == (2 * hidden_dim)\n","    x_len ~ [batch_size]\n","    '''\n","\n","    #[batch_size, seq_len, 1]\n","    e_ij = torch.matmul(\n","                torch.tanh( \n","                      torch.matmul(x, #[batch_size, seq_len, feature_dim]\n","                                   self.W #[feature_dim, feature_dim]\n","                                  ) #[batch_size, seq_len, feature_dim]\n","                ), #[batch_size, seq_len, feature_dim]\n","                self.u #[feature_dim, 1]\n","            ) #[batch_size, seq_len, 1]\n","\n","   \n","    #[batch_size, seq_len, 1]\n","    a_ij = torch.softmax(e_ij, dim=1)\n","\n","    # multiply each hidden state with the attention weights\n","    #[batch_size, seq_len, feature_dim]\n","    weighted_ip = x * a_ij\n","\n","    return weighted_ip, a_ij\n","    \n","\n","class Classifier(nn.Module):\n","\n","  def __init__(self, vocab_size, **kwargs):\n","    #Constructor\n","    super(Classifier, self).__init__(**kwargs)\n","\n","    # variables\n","    self.embedding_dim = 100\n","    self.hidden_dim = 32\n","    self.num_layers = 1\n","    self.bidirectional = True\n","    self.batch_first = True\n","    self.output_dim = 1\n","\n","    #embedding layer\n","    self.embedding = nn.Embedding(num_embeddings=vocab_size, \n","                                  embedding_dim=self.embedding_dim)\n","\n","    #lstm layer\n","    self.lstm = nn.LSTM(input_size=self.embedding_dim,\n","                        hidden_size=self.hidden_dim, \n","                        num_layers=self.num_layers, \n","                        bidirectional=self.bidirectional,\n","                        batch_first=self.batch_first)\n","    \n","    self.attn = Attention(self.hidden_dim * 2, batch_first=True) # 2 is bidrectional\n","\n","    #dense layer / linear layer\n","    self.fc = nn.Linear(self.hidden_dim * 2, self.output_dim)\n","\n","    #activation function\n","    self.act = nn.Sigmoid()\n","\n","  def forward(self, txt, txt_len):\n","    '''\n","    # txt [batch_size, seq_len] \n","    ~ seq_len is max sequence length among all the rows in batch\n","    ~ it means the rows length with less than seq_len will be padded with zeros\n","    ~ but the padding will be batchwise\n","    # txt_len [batch_size]\n","    ~ contains sequence length for each row in batch\n","    '''\n","    \n","    '''\n","    Step 1: pass through the embedding layer to convert text into vectors\n","    '''\n","    # embed_txt ~ [batch_size, seq_len, embedding_dim] \n","    embed_txt = self.embedding(txt)\n","\n","    '''\n","    Step 2: passing the embeddings through LSTM layer\n","    '''\n","\n","    '''\n","    Step 2.1: first packing the embeddings to tackle variable length input\n","    '''\n","    # packed the embedding (only the vocab words without padding)\n","    embed_txt_packed_pad = nn.utils.rnn.pack_padded_sequence(embed_txt, txt_len, batch_first=True)\n","\n","\n","    '''\n","    Step 2.2: passing the packed input to LSTM layer\n","    '''\n","    # LSTM block \n","    lstm_out, (h_n, c_n) = self.lstm(embed_txt_packed_pad)\n","\n","\n","    '''\n","    Step 2.3: retrieving back the lstm output with zero padding\n","    '''\n","    # packed the embedding (with padding)\n","    embed_txt_pad_packed, lengths = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n","\n","\n","    # embed_txt_pad_packed ~ [batch_size, seq_len, embedding_dim] \n","\n","\n","    '''\n","    Step 3: passing the lstm output to Attention layer to get weighted output sequence\n","    '''\n","    # attn_out ~ [batch_size, (2 * hidden_dim)]\n","    attn_out, _ = self.attn(embed_txt_pad_packed, lengths, mask=None)\n","\n","    '''\n","    sum all the weighted hidden states (modified by attention)\n","    '''\n","    # [batch_size, feature_dim]\n","    weighted_sum_ip = attn_out.sum(dim=1)\n","\n","    '''\n","    feeding the weighted value to a linear layer\n","    '''\n","    # fc_out ~ [batch_size, output_dim]\n","    fc_out = self.fc(weighted_sum_ip)\n","\n","    '''\n","    feeding the linear output to activation function\n","    '''\n","    # out ~ [batch_size, output_dim]\n","    out = self.act(fc_out)\n","\n","    return out"],"metadata":{"id":"I8v8UZ2GNykd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define hyperparameters\n","vocab_size = len(TEXT.vocab)\n","\n","#instantiate the model\n","train_model = Classifier(vocab_size)\n","train_model = train_model.to(device)"],"metadata":{"id":"hWLNPJT3AOQL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define metric\n","def binary_accuracy(preds, y):\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(preds)\n","    \n","    correct = (rounded_preds == y).float() \n","    acc = correct.sum() / len(correct)\n","    return acc"],"metadata":{"id":"pTt99WI1ARZx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def valid_model(valid_iterator, train_model, criterion):\n","  epoch_loss = 0\n","  epoch_acc = 0\n","\n","  with torch.no_grad():\n","    for valid_batch in valid_iterator:\n","      \n","      #retrieve text and no. of words\n","      text, text_lengths = valid_batch.text\n","          \n","      #get prediction\n","      predictions = train_model(text, text_lengths)\n","      preds = predictions.squeeze(-1) #convert to 1D tensor\n","\n","      #compute the loss\n","      loss = criterion(preds, valid_batch.label)\n","\n","      #compute the binary accuracy\n","      acc = binary_accuracy(preds, valid_batch.label)\n","\n","      # compute loss and accuracy\n","      epoch_loss += loss.item()\n","      epoch_acc += acc.item()\n","\n","  valid_epoc_loss = epoch_loss / len(valid_iterator)\n","  valid_epoch_acc = epoch_acc / len(valid_iterator)\n","\n","  return valid_epoc_loss, valid_epoch_acc"],"metadata":{"id":"L692DPeLTdEz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#training the model\n","\n","#define the optimizer\n","optimizer = optim.Adam(train_model.parameters())\n","\n","#define the loss\n","criterion = nn.BCELoss()\n","criterion = criterion.to(device)\n","\n","#set the model in training phase\n","train_model.train()\n","\n","N_EPOCHS = 6\n","VALIDATION_EPOCH = 2\n","\n","for epoch in range(N_EPOCHS+1):\n","\n","  #initialize every epoch \n","  epoch_loss = 0\n","  epoch_acc = 0\n","\n","  for batch in train_iterator:\n","    #resets the gradients after every batch\n","    optimizer.zero_grad() \n","\n","    #retrieve text and no. of words\n","    text, text_lengths = batch.text\n","\n","    #get prediction\n","    predictions = train_model(text, text_lengths)\n","    preds = predictions.squeeze(-1) #convert to 1D tensor\n","\n","    #compute the loss\n","    loss = criterion(preds, batch.label)\n","\n","    #compute the binary accuracy\n","    acc = binary_accuracy(preds, batch.label)   \n","\n","    #backpropage the loss and compute the gradients\n","    loss.backward()\n","\n","    #update the weights\n","    optimizer.step() \n","\n","    # compute loss and accuracy\n","    epoch_loss += loss.item()\n","    epoch_acc += acc.item()\n","\n","  if epoch%VALIDATION_EPOCH == 0:\n","    train_model.eval() # set the model in eval phase\n","    valid_epoc_loss, valid_epoch_acc = valid_model(valid_iterator, train_model, criterion)\n","    train_model.train() # return back to training phase\n","\n","    print(\"epoch:- \",epoch)\n","    print(\"training===> \",\"loss:- \", epoch_loss / len(train_iterator), \"  accuracy:- \", epoch_acc / len(train_iterator))\n","    print(\"validation===> \",\"loss:- \", valid_epoc_loss, \"  accuracy:- \", valid_epoch_acc)\n","\n","  if epoch == N_EPOCHS-1:\n","    torch.save(train_model.state_dict(), g_path+\"model/classification_model.pt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QZhRwRmFAWFE","executionInfo":{"status":"ok","timestamp":1651168433275,"user_tz":300,"elapsed":49828,"user":{"displayName":"Jaydeep Chakraborty","userId":"04716741579620071152"}},"outputId":"002a9876-ca3f-48f4-9ebb-b8e63c93d1bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:-  0\n","training===>  loss:-  0.6995312401226589   accuracy:-  0.4857142950807299\n","validation===>  loss:-  0.6951013008753458   accuracy:-  0.4000000059604645\n","epoch:-  2\n","training===>  loss:-  0.639090929712568   accuracy:-  0.8571428656578064\n","validation===>  loss:-  0.7025701999664307   accuracy:-  0.46666667858759564\n","epoch:-  4\n","training===>  loss:-  0.5566349625587463   accuracy:-  0.9428571462631226\n","validation===>  loss:-  0.703237255414327   accuracy:-  0.5333333412806193\n","epoch:-  6\n","training===>  loss:-  0.4354144334793091   accuracy:-  0.9714285731315613\n","validation===>  loss:-  0.7122084498405457   accuracy:-  0.5333333412806193\n"]}]},{"cell_type":"code","source":["###  Inference  ###\n","\n","#define hyperparameters\n","vocab_size = len(TEXT.vocab)\n","\n","#instantiate the model\n","test_model = Classifier(vocab_size)\n","test_model = test_model.to(device)\n","\n","#loading the model\n","model_path = g_path+\"model/classification_model.pt\"\n","test_model.load_state_dict(torch.load(model_path))\n","\n","test_model.eval() # set the model in eval phase\n","\n","\n","test_sentence = \"Are there any sports that you don't like?\"\n","test_sentence = \"I love the movie\"\n","test_sentence = \"I dislike the movie\"\n","test_sentence = \"I don't like the movie\"\n","\n","test_data = \" \".join(clean_data(test_sentence.split(\" \"))) # clean the data\n","tokenized_test_data = tokenizer(test_data)  #tokenize the sentence\n","\n","indexed_test_data = [TEXT.vocab.stoi[t] for t in tokenized_test_data]  #convert to integer sequence\n","txt_tensor = torch.LongTensor(indexed_test_data).to(device) #convert to tensor\n","txt_tensor_ip = txt_tensor.unsqueeze(1).T #reshape in form of batch,no. of words\n","\n","length = [len(indexed_test_data)]  #compute no. of words\n","length_tensor_ip = torch.LongTensor(length) #convert to tensor \n","\n","prediction = test_model(txt_tensor_ip, length_tensor_ip) #prediction\n","\n","print(prediction.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gyf31XnuCsLt","executionInfo":{"status":"ok","timestamp":1651168477532,"user_tz":300,"elapsed":130,"user":{"displayName":"Jaydeep Chakraborty","userId":"04716741579620071152"}},"outputId":"4aa79395-0f39-4235-9e00-683e909c2169"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.45333701372146606\n"]}]},{"cell_type":"markdown","source":["**Example>>>>**\n","\n","---\n","\n"],"metadata":{"id":"g-VzOYvqTwuZ"}},{"cell_type":"code","source":["#[batch_size, (seq_len ~ variable), embed_dim]\n","x = [\n","        [\n","         [0.16, 0.57, 0.12, 0.84],\n","         [0.64, 0.28, 0.42, 0.86]\n","        ],\n","\n","        [\n","         [0.20, 0.91, 0.26, 0.16],\n","         [0.75, 0.32, 0.25, 0.75],\n","         [0.15, 0.16, 0.70, 0.48]\n","        ],\n","\n","        [\n","         [0.91, 0.10, 0.74, 0.22],\n","         [0.25, 0.42, 0.29, 0.26],\n","         [0.51, 0.70, 0.12, 0.26]\n","        ],\n","\n","        [\n","         [0.17, 0.91, 0.77, 0.88]\n","        ],\n","\n","        [\n","         [0.35, 0.90, 0.18, 0.46],\n","         [0.44, 0.33, 0.16, 0.43],\n","         [0.10, 0.97, 0.10, 0.70]\n","        ]\n","      ]"],"metadata":{"id":"Vmc-c4b2UDkt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","first define the input to the attention\n","#[batch_size, seq_len, embed_dim]\n","batch_size : the number of input sentences at a time\n","seq_len : the number (max) of words among the input sentences\n","embed_dim : the vector dimension for each word (depends on RNN/LSTM hidden_dim)\n","'''\n","\n","batch_size = 5\n","seq_len = 3\n","embed_dim = 4\n","\n","#[batch_size, seq_len, embed_dim]\n","x_padded = torch.Tensor([\n","        [[0.16, 0.57, 0.12, 0.84],\n","         [0.64, 0.28, 0.42, 0.86],\n","         [0.41,  0.4, 0.12, 0.82]],\n","\n","        [[ 0.2, 0.91, 0.26, 0.16],\n","         [0.75, 0.32, 0.25, 0.75],\n","         [0.15, 0.16,  0.7, 0.48]],\n","\n","        [[0.91, 0.10, 0.74, 0.22],\n","         [0.25, 0.42, 0.29, 0.26],\n","         [0.51, 0.70, 0.12, 0.26]],\n","\n","        [[0.17, 0.91, 0.77, 0.88],\n","         [0.10, 0.14, 0.60, 0.74],\n","         [0.94, 0.43, 0.77, 0.95]],\n","\n","        [[0.35,  0.9, 0.18, 0.46],\n","         [0.44, 0.33, 0.16, 0.43],\n","         [ 0.1, 0.97,  0.1,  0.7]]\n","      ])"],"metadata":{"id":"XpGBSuAdluRx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","let's define the weights to be learned \n","these weights will help us to learn attention weights for earch word in each sentence\n","--> these should be randomly initialized at begining\n","--> these should be defined as nn.Parameter so it can be learned by backward propagation \n","'''\n","#[embed_dim, embed_dim]\n","W = torch.Tensor([\n","        [-0.88, 0.09, 0.04,  0.00],\n","        [0.37,  0.00, 0.37,  0.83],\n","        [0.94,  0.37, 0.40,  0.93],\n","        [0.72,  0.28, 0.09,  0.00]])\n","\n","#[embed_dim, 1]\n","u = torch.Tensor([\n","        [0.72],\n","        [0.3],\n","        [0.64],\n","        [0.00]])"],"metadata":{"id":"FrQCIeskAElM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#[batch_size, seq_len, embed_dim] \n","tmp_1 = torch.matmul(x_padded,W)\n","print(\"first matmul shape:- \\n\",tmp_1.shape)\n","print(\"first matmul:- \\n\",tmp_1)\n","\n","#[batch_size, seq_len, embed_dim] \n","tmp_2 = torch.tanh(tmp_1)\n","print(\"tanh shape:- \\n\",tmp_2.shape)\n","print(\"tanh:- \\n\",tmp_2)\n","\n","#[batch_size, seq_len, 1] \n","tmp_3 = torch.matmul(tmp_2, u)\n","print(\"second matmul shape:- \\n\",tmp_3.shape)\n","print(\"second matmul:- \\n\",tmp_3)\n","\n","\n","#[batch_size, seq_len, 1]\n","attn = torch.matmul(\n","    torch.tanh( torch.matmul(x_padded, #[batch_size, seq_len, embed_dim] \n","                                W #[embed_dim, embed_dim]\n","                              ) #[batch_size, seq_len]\n","    ),\n","    u #[embed_dim, 1]\n",")"],"metadata":{"id":"QTOjosFbAUXS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651168582392,"user_tz":300,"elapsed":132,"user":{"displayName":"Jaydeep Chakraborty","userId":"04716741579620071152"}},"outputId":"70b36caa-7055-467e-ddf3-fb05aa0fa0b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["first matmul shape:- \n"," torch.Size([5, 3, 4])\n","first matmul:- \n"," tensor([[[0.7877, 0.2940, 0.3409, 0.5847],\n","         [0.5544, 0.4538, 0.3746, 0.6230],\n","         [0.4904, 0.3109, 0.2862, 0.4436]],\n","\n","        [[0.5203, 0.1590, 0.4631, 0.9971],\n","         [0.2334, 0.3700, 0.3159, 0.4981],\n","         [0.9308, 0.4069, 0.3884, 0.7838]],\n","\n","        [[0.0902, 0.4173, 0.3892, 0.7712],\n","         [0.3952, 0.2026, 0.3048, 0.6183],\n","         [0.1102, 0.1631, 0.3508, 0.6926]],\n","\n","        [[1.5445, 0.5466, 0.7307, 1.4714],\n","         [1.0606, 0.4382, 0.3624, 0.6742],\n","         [0.7397, 0.6355, 0.5902, 1.0730]],\n","\n","        [[0.5254, 0.2269, 0.4604, 0.9144],\n","         [0.1949, 0.2192, 0.2424, 0.4227],\n","         [0.8689, 0.2420, 0.4659, 0.8981]]])\n","tanh shape:- \n"," torch.Size([5, 3, 4])\n","tanh:- \n"," tensor([[[0.6571, 0.2858, 0.3283, 0.5261],\n","         [0.5038, 0.4250, 0.3580, 0.5532],\n","         [0.4545, 0.3013, 0.2786, 0.4166]],\n","\n","        [[0.4779, 0.1577, 0.4326, 0.7604],\n","         [0.2293, 0.3540, 0.3058, 0.4606],\n","         [0.7310, 0.3858, 0.3700, 0.6549]],\n","\n","        [[0.0900, 0.3947, 0.3707, 0.6476],\n","         [0.3758, 0.1999, 0.2957, 0.5499],\n","         [0.1098, 0.1617, 0.3371, 0.5996]],\n","\n","        [[0.9129, 0.4980, 0.6235, 0.8998],\n","         [0.7859, 0.4122, 0.3473, 0.5877],\n","         [0.6290, 0.5618, 0.5300, 0.7906]],\n","\n","        [[0.4819, 0.2231, 0.4304, 0.7232],\n","         [0.1925, 0.2158, 0.2378, 0.3992],\n","         [0.7008, 0.2374, 0.4349, 0.7154]]])\n","second matmul shape:- \n"," torch.Size([5, 3, 1])\n","second matmul:- \n"," tensor([[[0.7690],\n","         [0.7194],\n","         [0.5960]],\n","\n","        [[0.6683],\n","         [0.4670],\n","         [0.8788]],\n","\n","        [[0.4204],\n","         [0.5198],\n","         [0.3433]],\n","\n","        [[1.2057],\n","         [0.9118],\n","         [0.9606]],\n","\n","        [[0.6893],\n","         [0.3555],\n","         [0.8541]]])\n"]}]},{"cell_type":"code","source":["#[batch_size, seq_len, 1]\n","attn_score = torch.softmax(attn, dim=1)\n","print(\"attn_score shape:- \\n\", attn_score.shape)\n","print(\"attn_score:- \\n\", attn_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xqXhIq3XUSqT","executionInfo":{"status":"ok","timestamp":1651168593503,"user_tz":300,"elapsed":171,"user":{"displayName":"Jaydeep Chakraborty","userId":"04716741579620071152"}},"outputId":"87054e0a-c188-4a6f-8bd9-d34ee42005fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["attn_score shape:- \n"," torch.Size([5, 3, 1])\n","attn_score:- \n"," tensor([[[0.3581],\n","         [0.3407],\n","         [0.3012]],\n","\n","        [[0.3277],\n","         [0.2679],\n","         [0.4044]],\n","\n","        [[0.3300],\n","         [0.3645],\n","         [0.3055]],\n","\n","        [[0.3956],\n","         [0.2948],\n","         [0.3096]],\n","\n","        [[0.3454],\n","         [0.2474],\n","         [0.4073]]])\n"]}]},{"cell_type":"code","source":["#[batch_size, seq_len, embed_dim] \n","weighted_x = x_padded * attn_score\n","print(\"weighted_x shape:- \\n\", weighted_x.shape)\n","print(\"weighted_x:- \\n\", weighted_x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haHuT205UVOI","executionInfo":{"status":"ok","timestamp":1651168610092,"user_tz":300,"elapsed":137,"user":{"displayName":"Jaydeep Chakraborty","userId":"04716741579620071152"}},"outputId":"23720ded-0dad-41e9-b558-e1d000ce2202"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["weighted_x shape:- \n"," torch.Size([5, 3, 4])\n","weighted_x:- \n"," tensor([[[0.0573, 0.2041, 0.0430, 0.3008],\n","         [0.2181, 0.0954, 0.1431, 0.2930],\n","         [0.1235, 0.1205, 0.0361, 0.2470]],\n","\n","        [[0.0655, 0.2982, 0.0852, 0.0524],\n","         [0.2009, 0.0857, 0.0670, 0.2009],\n","         [0.0607, 0.0647, 0.2831, 0.1941]],\n","\n","        [[0.3003, 0.0330, 0.2442, 0.0726],\n","         [0.0911, 0.1531, 0.1057, 0.0948],\n","         [0.1558, 0.2139, 0.0367, 0.0794]],\n","\n","        [[0.0672, 0.3600, 0.3046, 0.3481],\n","         [0.0295, 0.0413, 0.1769, 0.2182],\n","         [0.2910, 0.1331, 0.2384, 0.2941]],\n","\n","        [[0.1209, 0.3108, 0.0622, 0.1589],\n","         [0.1088, 0.0816, 0.0396, 0.1064],\n","         [0.0407, 0.3950, 0.0407, 0.2851]]])\n"]}]},{"cell_type":"code","source":["#[batch_size, embed_dim] \n","weighted_sum_x = torch.sum(weighted_x, dim=1)\n","print(\"weighted_sum_x shape:- \\n\", weighted_sum_x.shape)\n","print(\"weighted_sum_x:- \\n\", weighted_sum_x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MuavGqwMUZFR","executionInfo":{"status":"ok","timestamp":1651168621757,"user_tz":300,"elapsed":152,"user":{"displayName":"Jaydeep Chakraborty","userId":"04716741579620071152"}},"outputId":"4f1a911d-d9bf-4601-9584-f84c777f9745"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["weighted_sum_x shape:- \n"," torch.Size([5, 4])\n","weighted_sum_x:- \n"," tensor([[0.3989, 0.4200, 0.2222, 0.8408],\n","        [0.3271, 0.4486, 0.4353, 0.4475],\n","        [0.5472, 0.3999, 0.3866, 0.2468],\n","        [0.3877, 0.5344, 0.7199, 0.8604],\n","        [0.2704, 0.7875, 0.1425, 0.5503]])\n"]}]},{"cell_type":"markdown","source":["**Resources**\n","\n","---\n","**Link** <br>\n","1) https://www.kaggle.com/code/dannykliu/lstm-with-attention-clr-in-pytorch/notebook <br>\n","2) https://discuss.pytorch.org/t/self-attention-on-words-and-masking/5671/9 <br>\n","3) https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/ <br>\n","4) https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/ <br>\n","5) https://www.kaggle.com/code/robertke94/pytorch-bi-lstm-attention/notebook <br>\n","6) https://towardsdatascience.com/sequence-2-sequence-model-with-attention-mechanism-9e9ca2a613a <br>\n","7) https://towardsdatascience.com/attention-and-its-different-forms-7fc3674d14dc <br>\n","8) https://www.kaggle.com/code/pavelvod/transformer-cnn-lstm-attention-heads <br>\n","9) https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/ <br>\n","10) https://analyticsindiamag.com/hands-on-guide-to-bi-lstm-with-attention/ <br>\n","11) https://colab.research.google.com/drive/1HmegzNQR6g5_Xt37BMgV0kX7wQklT7dD?usp=sharing#scrollTo=Vh9bXvzHkmfi <br>\n","12) https://github.com/prakashpandey9/Text-Classification-Pytorch <br>\n","13) https://www.programmerall.com/article/51852224642/ <br>\n","14) https://richliao.github.io/supervised/classification/2016/12/26/textclassifier-RNN/ <br>\n","15) https://richliao.github.io/supervised/classification/2016/12/26/textclassifier-HATN/ <br>\n","16) https://lilianweng.github.io/posts/2018-06-24-attention/ <br>\n","17) https://github.com/WHLYA/text-classification/blob/master/text%20classification/LSTM%2BAttention.ipynb <br>\n","\n","**Video** <br>\n","1) https://www.youtube.com/watch?v=Bp-_DatyUCY <br>\n","2) https://www.youtube.com/watch?v=oaV_Fv5DwUM <br>\n","3) https://www.youtube.com/watch?v=KmAISyVvE1Y <br>\n","4) https://www.youtube.com/watch?v=oUhGZMCTHtI <br>\n","5) https://www.youtube.com/watch?v=MN__lSncZBs <br>\n","6) https://www.coursera.org/lecture/nlp-sequence-models/attention-model-intuition-RDXpX\n","\n","**Paper** <br>\n","1) https://arxiv.org/pdf/1904.02874.pdf <br>\n","2) https://arxiv.org/pdf/1409.0473.pdf <br>\n","3) https://arxiv.org/pdf/1804.06659.pdf <br>\n","4) https://arxiv.org/pdf/1703.03130.pdf <br>\n","5) https://arxiv.org/ftp/arxiv/papers/1902/1902.02181.pdf <br>\n","6) https://mdpi-res.com/d_attachment/applsci/applsci-11-03883/article_deploy/applsci-11-03883.pdf?version=1619361335 <br>\n","7) https://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf <br>\n","8) https://colinraffel.com/publications/iclr2016feed.pdf <br>\n","9) http://univagora.ro/jour/index.php/ijccc/article/download/3142/1185/ "],"metadata":{"id":"IEE9oinZT3vn"}}]}