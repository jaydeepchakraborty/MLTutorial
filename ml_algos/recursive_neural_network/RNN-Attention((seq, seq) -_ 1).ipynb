{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8UXGjd1EQrF"
   },
   "source": [
    "--> Recurrent Neural Networks (RNNs) have been used successfully for many tasks involving sequential data such as machine translation, sentiment analysis, image captioning, time-series prediction etc. <br>\n",
    "--> Improved RNN models such as Long Short-Term Memory networks (LSTMs) enable training on long sequences overcoming problems like vanishing gradients. <br>\n",
    "--> To improve further, Attention is a mechanism combined in the RNN allowing it to focus on certain parts of the input sequence when predicting a certain part of the output sequence, enabling easier learning and of higher quality. Combination of attention mechanisms enabled improved performance in many tasks making it an integral part of modern RNN networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1650439488049,
     "user": {
      "displayName": "Jaydeep Chakraborty",
      "userId": "04716741579620071152"
     },
     "user_tz": 300
    },
    "id": "gxVQMmz1DTOA"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import spacy\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchtext.legacy import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3760,
     "status": "ok",
     "timestamp": 1650439493546,
     "user": {
      "displayName": "Jaydeep Chakraborty",
      "userId": "04716741579620071152"
     },
     "user_tz": 300
    },
    "id": "FzjFWm3olRcZ",
    "outputId": "be3195e3-163d-4418-f01e-7597200b3850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "g_path = \"/content/drive/My Drive/pytorch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1650439496446,
     "user": {
      "displayName": "Jaydeep Chakraborty",
      "userId": "04716741579620071152"
     },
     "user_tz": 300
    },
    "id": "5fhlzLJSlhCC"
   },
   "outputs": [],
   "source": [
    "data_fl = 'data/quora_question_pair_small.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1650439499333,
     "user": {
      "displayName": "Jaydeep Chakraborty",
      "userId": "04716741579620071152"
     },
     "user_tz": 300
    },
    "id": "MbhJNUGslln_",
    "outputId": "f12e5ee2-0a03-4249-98ae-5c0169f25903"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4c8ccbbeb0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reproducing the same result\n",
    "SEED = 2021\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 901,
     "status": "ok",
     "timestamp": 1650439502639,
     "user": {
      "displayName": "Jaydeep Chakraborty",
      "userId": "04716741579620071152"
     },
     "user_tz": 300
    },
    "id": "YHmSv9rel5Dh"
   },
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en')\n",
    "def clean_data(texts):\n",
    "    cleaned_text = []\n",
    "    for text in texts:\n",
    "        # remove break\n",
    "        text = text.replace('br', '')\n",
    "        # remove punctuation\n",
    "        text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "        # remove multiple spaces\n",
    "        text = re.sub(r' +', ' ', text)\n",
    "        # remove newline\n",
    "        text = re.sub(r'\\n', ' ', text)\n",
    "        # strip the text\n",
    "        text = text.strip()\n",
    "        # lower the text\n",
    "        text = text.lower()\n",
    "\n",
    "        if text != '':\n",
    "          cleaned_text.append(text)\n",
    "    return cleaned_text\n",
    "\n",
    "def tokenizer(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "TEXT = data.Field(preprocessing=clean_data,tokenize=tokenizer,batch_first=True,include_lengths=True)\n",
    "LABEL = data.LabelField(dtype = torch.float,batch_first=True)\n",
    "fields = [(None, None), (None, None), (None, None), ('q1_txt',TEXT), ('q2_txt',TEXT),('label', LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1484,
     "status": "ok",
     "timestamp": 1650439507498,
     "user": {
      "displayName": "Jaydeep Chakraborty",
      "userId": "04716741579620071152"
     },
     "user_tz": 300
    },
    "id": "2U2OKcGrmE4Z",
    "outputId": "4f1320c1-ea4d-4988-b059-98f8e8092d92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q1_txt': ['what', 'is', 'the', 'story', 'of', 'kohinoor', 'koh', 'i', 'noor', 'diamond'], 'q2_txt': ['what', 'would', 'happen', 'if', 'the', 'indian', 'government', 'stole', 'the', 'kohinoor', 'koh', 'i', 'noor', 'diamond', 'back'], 'label': '0'}\n",
      "['what', 'is', 'the', 'story', 'of', 'kohinoor', 'koh', 'i', 'noor', 'diamond']\n",
      "['what', 'would', 'happen', 'if', 'the', 'indian', 'government', 'stole', 'the', 'kohinoor', 'koh', 'i', 'noor', 'diamond', 'back']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#loading the entire data\n",
    "def load_data():\n",
    "  quora_data = data.TabularDataset(path = g_path+data_fl,format = 'csv', fields = fields, skip_header = True)\n",
    "  return quora_data\n",
    "\n",
    "quora_data = load_data() \n",
    "print(vars(quora_data.examples[1]))\n",
    "print(quora_data.examples[1].q1_txt)\n",
    "print(quora_data.examples[1].q2_txt)\n",
    "print(quora_data.examples[1].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1650439512284,
     "user": {
      "displayName": "Jaydeep Chakraborty",
      "userId": "04716741579620071152"
     },
     "user_tz": 300
    },
    "id": "nMGzvFeCoC4x"
   },
   "outputs": [],
   "source": [
    "#deleting blank data\n",
    "blank_idx = []\n",
    "for i in range(len(quora_data.examples)):\n",
    "  if(len(quora_data.examples[i].q1_txt) == 0 or len(quora_data.examples[i].q2_txt) == 0):\n",
    "    print(i)\n",
    "    blank_idx.append(i)\n",
    "\n",
    "for i in range(len(blank_idx)):\n",
    "  del quora_data.examples[blank_idx[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 145,
     "status": "ok",
     "timestamp": 1650439516057,
     "user": {
      "displayName": "Jaydeep Chakraborty",
      "userId": "04716741579620071152"
     },
     "user_tz": 300
    },
    "id": "q_-Sf6vnoJrX"
   },
   "outputs": [],
   "source": [
    "#splitting the data into training and validation dataset\n",
    "def split_data(quora_data):\n",
    "  train_data, valid_data = quora_data.split(split_ratio=0.7, random_state = random.seed(SEED))\n",
    "  return train_data, valid_data\n",
    "\n",
    "train_data, valid_data = split_data(quora_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1490,
     "status": "ok",
     "timestamp": 1650439520404,
     "user": {
      "displayName": "Jaydeep Chakraborty",
      "userId": "04716741579620071152"
     },
     "user_tz": 300
    },
    "id": "ZRQs9LRgoTj2",
    "outputId": "a1f69c0d-1b47-4f82-e379-921ad3a3c28d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TEXT vocabulary: 812\n",
      "Size of LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "#generate vocabulary\n",
    "TEXT.build_vocab(train_data,min_freq=3,vectors = \"glove.6B.100d\")  \n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "#No. of unique tokens in text\n",
    "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
    "#No. of unique tokens in label\n",
    "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1650439568632,
     "user": {
      "displayName": "Jaydeep Chakraborty",
      "userId": "04716741579620071152"
     },
     "user_tz": 300
    },
    "id": "GhFYd8CkoYRS"
   },
   "outputs": [],
   "source": [
    "#preparing batches for training the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "\n",
    "#set batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "#Load an iterator\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.q1_txt),\n",
    "    sort_within_batch=True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 158,
     "status": "ok",
     "timestamp": 1650440788883,
     "user": {
      "displayName": "Jaydeep Chakraborty",
      "userId": "04716741579620071152"
     },
     "user_tz": 300
    },
    "id": "6pYRvHejpr0M"
   },
   "outputs": [],
   "source": [
    "#define model architecture\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    \n",
    "    #define all the layers used in model\n",
    "    def __init__(self, vocab_size, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, output_dim, \n",
    "                 n_layers, bidirectional, dropout):\n",
    "        \n",
    "        #Constructor\n",
    "        super().__init__()          \n",
    "        \n",
    "        #embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        #lstm layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=num_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        #dense layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        #activation function\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [batch size,sent_length]\n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent_len, emb dim]\n",
    "      \n",
    "        #packed sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        #hidden = [batch size, num layers * num directions, hid dim]\n",
    "        #cell = [batch size, num layers * num directions, hid dim]\n",
    "        \n",
    "        #concat the final forward and backward hidden state\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        dense_outputs=self.fc(hidden)\n",
    "\n",
    "        #Final activation function\n",
    "        outputs=self.act(dense_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1650440800457,
     "user": {
      "displayName": "Jaydeep Chakraborty",
      "userId": "04716741579620071152"
     },
     "user_tz": 300
    },
    "id": "AqWczSidp55V"
   },
   "outputs": [],
   "source": [
    "#define hyperparameters\n",
    "vocab_size = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 32\n",
    "output_dim = 1\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.2\n",
    "\n",
    "#instantiate the model\n",
    "train_model = classifier(vocab_size, embedding_dim, \n",
    "                   hidden_dim,output_dim, \n",
    "                   num_layers, bidirectional = True, dropout = dropout)\n",
    "train_model = train_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1650439610756,
     "user": {
      "displayName": "Jaydeep Chakraborty",
      "userId": "04716741579620071152"
     },
     "user_tz": 300
    },
    "id": "gCaGquygp89C"
   },
   "outputs": [],
   "source": [
    "#define metric\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "    \n",
    "    correct = (rounded_preds == y).float() \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1715,
     "status": "ok",
     "timestamp": 1650440894068,
     "user": {
      "displayName": "Jaydeep Chakraborty",
      "userId": "04716741579620071152"
     },
     "user_tz": 300
    },
    "id": "Zixt2J8ap_1g",
    "outputId": "d162c264-3052-405b-ce49-50c034333d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-  0.668851608579809\n",
      "accuracy:-  39.65625\n",
      "loss:-  0.6317416700449857\n",
      "accuracy:-  41.18181818181818\n",
      "loss:-  0.6169563369317488\n",
      "accuracy:-  41.18181818181818\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "\n",
    "#define the optimizer\n",
    "optimizer = optim.Adam(train_model.parameters())\n",
    "\n",
    "#define the loss\n",
    "criterion = nn.BCELoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "#set the model in training phase\n",
    "train_model.train()\n",
    "\n",
    "N_EPOCHS = 3\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "  #initialize every epoch \n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "\n",
    "  for batch in train_iterator:\n",
    "    #resets the gradients after every batch\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    #retrieve text and no. of words\n",
    "    q1_txt, q1_text_lengths = batch.q1_txt\n",
    "    q2_txt, q2_text_lengths = batch.q2_txt\n",
    "\n",
    "    #get prediction\n",
    "    predictions = train_model(q1_txt, q1_text_lengths)\n",
    "    preds = predictions.squeeze() #convert to 1D tensor\n",
    "\n",
    "    #compute the loss\n",
    "    loss = criterion(preds, batch.label)\n",
    "\n",
    "    #compute the binary accuracy\n",
    "    acc = binary_accuracy(predictions, batch.label)   \n",
    "\n",
    "    #backpropage the loss and compute the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    #update the weights\n",
    "    optimizer.step() \n",
    "\n",
    "    #compute loss and accuracy\n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += acc.item()\n",
    "\n",
    "  print(\"loss:- \", epoch_loss / len(train_iterator))\n",
    "  print(\"accuracy:- \", epoch_acc / len(train_iterator))\n",
    "\n",
    "  if epoch == N_EPOCHS-1:\n",
    "    torch.save(train_model.state_dict(), g_path+\"model/classification_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDCmCQg1qGzw"
   },
   "outputs": [],
   "source": [
    "#define hyperparameters\n",
    "vocab_size = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 32\n",
    "output_dim = 1\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.2\n",
    "\n",
    "#instantiate the model\n",
    "test_model = classifier(vocab_size, embedding_dim, \n",
    "                   hidden_dim,output_dim, \n",
    "                   num_layers, bidirectional = True, dropout = dropout)\n",
    "test_model = test_model.to(device)\n",
    "\n",
    "#loading the model\n",
    "model_path = g_path+\"model/classification_model.pt\"\n",
    "test_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_model.eval()\n",
    "\n",
    "def predict(test_model, sentence):\n",
    "  tokenized = [tok.text for tok in spacy_en.tokenizer(clean_data(sentence))]  #tokenize the sentence\n",
    "  indexed = [TEXT.vocab.stoi[t] for t in tokenized]                           #convert to integer sequence\n",
    "  txt_tensor = torch.LongTensor(indexed).to(device)                           #convert to tensor\n",
    "  txt_tensor_ip = txt_tensor.unsqueeze(1).T                                   #reshape in form of batch,no. of words\n",
    "\n",
    "  length = [len(indexed)]                                                     #compute no. of words\n",
    "  length_tensor_ip = torch.LongTensor(length)                                 #convert to tensor\n",
    "\n",
    "  prediction = test_model(txt_tensor_ip, length_tensor_ip)                    #prediction\n",
    "\n",
    "  print(prediction.item())\n",
    "\n",
    "\n",
    "predict(test_model, \"Are there any sports that you don't like?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEY2qW_DFtM4"
   },
   "source": [
    "**--- Resources ---**\n",
    "\n",
    "1) NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE (Dzmitry Bahdanau, KyungHyun Cho and Yoshua Bengio)\n",
    "https://arxiv.org/pdf/1409.0473.pdf <br>\n",
    "2) A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING\n",
    "https://arxiv.org/pdf/1703.03130.pdf <br>\n",
    "3) https://tomekkorbak.com/2020/06/26/implementing-attention-in-pytorch/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMPzYUn7VS3SZ2Jlh9lkUGp",
   "collapsed_sections": [],
   "name": "RNN-Attention((seq, seq) -> 1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
