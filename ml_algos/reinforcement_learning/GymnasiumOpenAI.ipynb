{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530b0ef5-dff7-4ff4-b719-19478b2f2f2a",
   "metadata": {},
   "source": [
    "--> Gymnasium is an open source Python library for developing simulated environment. <br>\n",
    "--> GIT: https://github.com/Farama-Foundation/Gymnasium <br>\n",
    "--> DOCUMENT:  https://gymnasium.farama.org/ <br>\n",
    "--> pip3 install \"gymnasium[all]\" <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66aaee3-ef07-44e7-a628-7ca9ddb300cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4ab2e-0b31-4be3-8cc5-aafc79be6fb9",
   "metadata": {},
   "source": [
    " # Existing Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c83a0f1e-d913-4298-a874-116c37cf82a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "observation, info = env.reset(seed=42)\n",
    "for _ in range(100):\n",
    "   action = env.action_space.sample()  # this is where you would insert your policy\n",
    "   observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "   if terminated or truncated:\n",
    "      observation, info = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef301b1d-5160-4ff9-ae25-79cc0297f70d",
   "metadata": {},
   "source": [
    "# Custom Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a277841f-a0f6-4997-a6a4-3372acbc6564",
   "metadata": {},
   "source": [
    "## Maze - v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c102a859-df19-4855-9deb-280665dec779",
   "metadata": {},
   "source": [
    "''' <br>\n",
    "<b>Components:</b> <br>\n",
    "&nbsp;    GRID/Maze: nxn matrix <br>\n",
    "&nbsp;    Agent: position is always at (0,0) ~ first cell <br>\n",
    "&nbsp;    Target: position is always at (-1,-1) ~ last cell <br>\n",
    "&nbsp;    Obstacles: position in multiple cells where Agent can not move <br>\n",
    "<b>Actions:</b> <br>\n",
    "&nbsp;    Agent can move 'up', 'down', 'left', 'right' <br>\n",
    "<b>Goal:</b> <br>\n",
    "&nbsp;    Agent should reach target <br>\n",
    "'''<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "572560c0-bff5-434f-8b65-32f64974f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, x=0, y=0):\n",
    "        self.name = 'MazeAgent'\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.val = 6 # this is to denote that cell contains the agent\n",
    "        self.action_happened = set()\n",
    "        self.last_action = ''\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Agent:- move: ({self.x} , {self.y}) ~ move happened: {self.action_happened} ~ last action: {self.last_action}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a7d36ce-dc6d-435b-a466-81a7731a953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MazeEnv(gym.Env):\n",
    "    \n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "    \n",
    "    # method -1\n",
    "    '''\n",
    "    The init method intialize all the variables needed.\n",
    "    '''\n",
    "    def __init__(self, conf, render_mode=None):\n",
    "        try:\n",
    "            \n",
    "            self.conf = conf\n",
    "            \n",
    "            # We have 4 actions, corresponding to \"right\", \"up\", \"left\", \"down\"\n",
    "            # It describes the numerical structure of the legitimate actions that can be applied to the environment.\n",
    "            self.action_space = spaces.Discrete(4)\n",
    "            \n",
    "            rows = self.conf['env']['rows']\n",
    "            cols = self.conf['env']['cols']\n",
    "            \n",
    "            # observation is the x, y coordinate of the grid - agent's current cell position\n",
    "            # for 4x4 maze, low pos: [0, 0] high pos: [3, 3]\n",
    "            low = np.array([0, 0], dtype=np.int64)\n",
    "            high = np.array([rows-1, cols-1], dtype=np.int64)\n",
    "            self.observation_space = spaces.Box(low, high, shape=(2,), dtype=np.int64)\n",
    "\n",
    "            \n",
    "            # generate environment\n",
    "            self.maze = np.zeros((rows, cols))\n",
    "\n",
    "            # generate dummy env for tracking agent's visited cels\n",
    "            self.visited = np.zeros((rows, cols))\n",
    "\n",
    "            # generate Agent, Agent will always start from (0,0) cell\n",
    "            self.agent = Agent(0, 0)\n",
    "            self._updt_agent_pos(self.agent)\n",
    "\n",
    "            # generate initial state of maze and agent\n",
    "            self._gen_init_state()\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    # method -2\n",
    "    '''\n",
    "    The reset method will be called to initiate a new episode. \n",
    "    '''\n",
    "    def reset(self, seed=None):\n",
    "        try:\n",
    "            # We need the following line to seed self.np_random\n",
    "            super().reset(seed=seed)\n",
    "            self._gen_init_state()\n",
    "            observation = self._get_obs()\n",
    "            info = self._get_info()\n",
    "            \n",
    "            return observation, info\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "     \n",
    "    # method -3\n",
    "    '''\n",
    "    The step method takes an action as an input and applies it to the environment, \n",
    "    which leads to the environment transitioning to a new state.\n",
    "    action: 'up', 'down', 'right', 'left'\n",
    "    '''\n",
    "    def step(self, action):\n",
    "        try:\n",
    "            # get the direction where agent should move\n",
    "            dir_num, dir_pos = self._action_to_direction(action)\n",
    "\n",
    "            # Whether the episode has been terminated\n",
    "            terminated = False\n",
    "            # The reward that you can get from the environment after executing the action \n",
    "            # that was given as the input to the step function.\n",
    "            reward = 0\n",
    "\n",
    "            # agent's new position\n",
    "            new_x = self.agent.x + dir_pos[0]\n",
    "            new_y = self.agent.y + dir_pos[1]\n",
    "\n",
    "            if not self._chk_pos_validity(new_x, new_y):\n",
    "                reward = -1 \n",
    "                self.agent.action_happened.add(action)\n",
    "                if len(self.agent.action_happened) == 4: # agent can not move any more\n",
    "                    terminated = True   \n",
    "            else:\n",
    "                self._updt_agent_pos(Agent(new_x, new_y))\n",
    "                self.agent.action_happened = set()\n",
    "                \n",
    "                terminated = True if self._win() else False\n",
    "                reward = 1 if terminated else 0.001\n",
    "\n",
    "            \n",
    "            self.agent.last_action = dir_num\n",
    "            \n",
    "            # The observation of the state of the environment.\n",
    "            observation = self._get_obs()\n",
    "            \n",
    "            # This provides additional information depending on the environment.\n",
    "            info = self._get_info()\n",
    "            \n",
    "            return observation, reward, terminated, False, info\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "    \n",
    "    # method -4\n",
    "    '''\n",
    "    The render method is for rendering the environment\n",
    "    '''\n",
    "    def render(self):\n",
    "        try:\n",
    "            self._visualize()\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    # method -5\n",
    "    '''\n",
    "    The close method should close any open resources that were used by the environment.\n",
    "    '''\n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    # translates the environmentâ€™s state into an observation\n",
    "    def _get_obs(self):\n",
    "        try:\n",
    "            return np.array([self.agent.x, self.agent.y], dtype=np.int64)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    # auxiliary information\n",
    "    def _get_info(self):\n",
    "        try:\n",
    "            return {\"visited\": self.visited}\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    # updating agent position in maze\n",
    "    def _updt_agent_pos(self, agent):\n",
    "        try:\n",
    "            self.agent.x = agent.x\n",
    "            self.agent.y = agent.y\n",
    "\n",
    "            self.visited[self.agent.x, self.agent.y] = 1\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    # checking agent position is valid or not in maze\n",
    "    def _chk_pos_validity(self,  x, y):\n",
    "        try:\n",
    "            rows = self.maze.shape[0]\n",
    "            cols = self.maze.shape[1]\n",
    "\n",
    "            # agent can not visit out of bound, obstacles, already visited cells\n",
    "            if x<0 or y<0 or x>=rows or y>=cols or self.maze[x][y] == -1 or self.visited[x][y] == 1:\n",
    "                return False\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    # condition for wining the game\n",
    "    def _win(self):\n",
    "        try:\n",
    "            if self.maze[self.agent.x, self.agent.y] == 1: # agent reached last cell\n",
    "                return True     \n",
    "            return False\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    \n",
    "    # It is for initializing maze and agent position\n",
    "    def _gen_init_state(self):\n",
    "        try:\n",
    "            # target will be always at the last cell\n",
    "            self.maze[-1, -1] = 1\n",
    "\n",
    "            # placing obstacles in maze\n",
    "            self.maze[0, 1:3] = -1\n",
    "            self.maze[1, 2:] = -1\n",
    "            self.maze[2, 0] = -1\n",
    "            self.maze[3, 0:2] = -1\n",
    "\n",
    "            # replacing agent at (0, 0) cell\n",
    "            self._updt_agent_pos(Agent(0, 0))\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    # It is for visualizing the maze's current position\n",
    "    def _visualize(self):\n",
    "        try:\n",
    "            maze = self.maze.copy()\n",
    "            maze[self.agent.x, self.agent.y] = self.agent.val\n",
    "            print(self.agent)\n",
    "            print(maze)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "    # converting action to direction\n",
    "    def _action_to_direction(self, action_num):\n",
    "        try:\n",
    "            ACTION = [\"down\", \"right\", \"up\", \"left\"]\n",
    "            \n",
    "            \n",
    "            action = {\n",
    "                'down': np.array([1, 0]),\n",
    "                'right': np.array([0, 1]),\n",
    "                'up': np.array([-1, 0]),\n",
    "                'left': np.array([0, -1]),\n",
    "            }\n",
    "            \n",
    "            return ACTION[action_num], action[ACTION[action_num]]\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "441f5c38-21c7-4f00-9cf3-69a8e45bb081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf():\n",
    "    try:\n",
    "        conf = {\n",
    "            'env':{\n",
    "                    'rows': 4,\n",
    "                    'cols': 4\n",
    "                }\n",
    "        }       \n",
    "        return conf\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2324ba1e-3e7e-4bbb-9482-4225fe5bc8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_env(env):\n",
    "    try:\n",
    "        \n",
    "        # checking using manual check\n",
    "        test_episodes = 2\n",
    "\n",
    "        for episode in range(1, test_episodes+1):\n",
    "\n",
    "            obs, info = env.reset()\n",
    "            terminated = False\n",
    "            score = 0\n",
    "\n",
    "            while not terminated:\n",
    "                env.render()\n",
    "                action = env.action_space.sample()\n",
    "                obs, reward, terminated, truncated, info = env.step(action)\n",
    "                score += reward\n",
    "\n",
    "            env.render()\n",
    "            print(f\"after episode:- {episode}, score:- {score}\")\n",
    "\n",
    "        env.close()\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34092536-9c99-4a1e-9ce5-2b95b7f3d37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent:- move: (0 , 0) ~ move happened: set() ~ last action: \n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {2} ~ last action: up\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {2} ~ last action: up\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {1, 2} ~ last action: right\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {1, 2, 3} ~ last action: left\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {1, 2, 3} ~ last action: right\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {1, 2, 3} ~ last action: right\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {1, 2, 3} ~ last action: left\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (1 , 0) ~ move happened: set() ~ last action: down\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 6.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (1 , 0) ~ move happened: {2} ~ last action: up\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 6.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (1 , 1) ~ move happened: set() ~ last action: right\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  6. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (1 , 1) ~ move happened: {1} ~ last action: right\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  6. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (1 , 1) ~ move happened: {1} ~ last action: right\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  6. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (1 , 1) ~ move happened: {1, 2} ~ last action: up\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  6. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (1 , 1) ~ move happened: {1, 2, 3} ~ last action: left\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  6. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (1 , 1) ~ move happened: {1, 2, 3} ~ last action: right\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  6. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (1 , 1) ~ move happened: {1, 2, 3} ~ last action: right\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  6. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (2 , 1) ~ move happened: set() ~ last action: down\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  6.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (2 , 1) ~ move happened: {0} ~ last action: down\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  6.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (2 , 1) ~ move happened: {0, 2} ~ last action: up\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  6.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (2 , 2) ~ move happened: set() ~ last action: right\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  6.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (3 , 2) ~ move happened: set() ~ last action: down\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  6.  1.]]\n",
      "Agent:- move: (3 , 2) ~ move happened: {0} ~ last action: down\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  6.  1.]]\n",
      "Agent:- move: (3 , 2) ~ move happened: {0, 2} ~ last action: up\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  6.  1.]]\n",
      "Agent:- move: (3 , 3) ~ move happened: set() ~ last action: right\n",
      "[[ 0. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  6.]]\n",
      "after episode:- 1, score:- -16.995\n",
      "Agent:- move: (0 , 0) ~ move happened: set() ~ last action: right\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {3} ~ last action: left\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {1, 3} ~ last action: right\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {1, 3} ~ last action: left\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {1, 3} ~ last action: left\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {1, 3} ~ last action: left\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {1, 3} ~ last action: left\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {0, 1, 3} ~ last action: down\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {0, 1, 3} ~ last action: right\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {0, 1, 3} ~ last action: left\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {0, 1, 3} ~ last action: left\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {0, 1, 3} ~ last action: left\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {0, 1, 3} ~ last action: down\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {0, 1, 3} ~ last action: right\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {0, 1, 3} ~ last action: left\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {0, 1, 2, 3} ~ last action: up\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "after episode:- 2, score:- -15\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # get config\n",
    "        conf = get_conf()\n",
    "        \n",
    "        # Create the environment ~ MAZE\n",
    "        m = MazeEnv(conf)\n",
    "        \n",
    "        # checking whether environment is working or not\n",
    "        test_env(m) \n",
    "        \n",
    "        print(\"DONE\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01708ae6-d88d-405f-b1a3-5c0cb7d3b061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc6fc6d-63a0-4996-85f7-df740d20df0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64282c01-5e55-4820-a210-0a681a9bd5bd",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5e7581b-9225-4556-a038-6ab6b2f6baf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# it will generate discrete value beween [0, 1, 2, 3]\n",
    "discrete_space = spaces.Discrete(4)\n",
    "discrete_space_sample = discrete_space.sample()\n",
    "print(discrete_space_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9969d798-112e-4952-b25b-9f16195bbe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 10]\n"
     ]
    }
   ],
   "source": [
    "# it will generate grid value beween low and high\n",
    "box_space = spaces.Box(low = 0, high = 10, shape=(2,), dtype=int)\n",
    "box_space_sample = box_space.sample()\n",
    "print(box_space_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04c4a2f8-080f-4acc-956e-dd685a2ed75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('agent', 2), ('target', array([0, 3]))])\n"
     ]
    }
   ],
   "source": [
    "# it will generate dictionary\n",
    "dict_space = spaces.Dict(\n",
    "    {\n",
    "        \"agent\": spaces.Discrete(4),\n",
    "        \"target\": spaces.Box(low = 0, high = 10, shape=(2,), dtype=int),\n",
    "    }\n",
    ")\n",
    "dict_space_sample = dict_space.sample()\n",
    "print(dict_space_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c875a-d64b-438f-83cf-3669e3b20971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
