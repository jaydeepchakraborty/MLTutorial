{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e38a8916-8702-4f76-9f7a-cbec15837208",
   "metadata": {},
   "source": [
    "--> Gym is an open source Python library for developing simulated environment. <br>\n",
    "--> GIT: https://github.com/openai/gym <br>\n",
    "--> DOCUMENT:  https://www.gymlibrary.dev/ <br>\n",
    "--> pip3 install \"gym[all]\" <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53c79921-2586-4443-948b-49cf8949380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb39a26e-f2ff-461a-bf66-13c4d7d3c998",
   "metadata": {},
   "source": [
    "# Existing Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66c2b580-98df-40aa-ab35-709ea151ebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action:- 0, reward:- 1.0\n",
      "action:- 0, reward:- 1.0\n",
      "action:- 1, reward:- 1.0\n",
      "action:- 0, reward:- 1.0\n",
      "action:- 0, reward:- 1.0\n",
      "action:- 1, reward:- 1.0\n",
      "action:- 0, reward:- 1.0\n",
      "action:- 0, reward:- 1.0\n",
      "action:- 1, reward:- 1.0\n",
      "action:- 0, reward:- 1.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "observation = env.reset()\n",
    "\n",
    "for _ in range(10):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, info = env.step(action)\n",
    "\n",
    "    print(f\"action:- {action}, reward:- {reward}\")\n",
    "    if terminated:\n",
    "        observation = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4095fdc6-7855-47b1-8d14-8533f681e233",
   "metadata": {},
   "source": [
    "# Custom Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d3f82f-6511-49d8-80a2-d3413536650d",
   "metadata": {},
   "source": [
    "## Maze - v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051a5d8-1c37-40ef-8d6f-b39bb7e3043f",
   "metadata": {},
   "source": [
    "''' <br>\n",
    "<b>Components:</b> <br>\n",
    "&nbsp;    GRID/Maze: nxn matrix <br>\n",
    "&nbsp;    Agent: position is always at (0,0) ~ first cell <br>\n",
    "&nbsp;    Target: position is always at (-1,-1) ~ last cell <br>\n",
    "&nbsp;    Obstacles: position in multiple cells where Agent can not move <br>\n",
    "<b>Actions:</b> <br>\n",
    "&nbsp;    Agent can move 'up', 'down', 'left', 'right' <br>\n",
    "<b>Goal:</b> <br>\n",
    "&nbsp;    Agent should reach target <br>\n",
    "'''<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a80607f-be75-4544-91a7-832aa86fb488",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, x=0, y=0):\n",
    "        self.name = 'MazeAgent'\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.val = 6 # this is to denote that cell contains the agent\n",
    "        self.action_happened = set()\n",
    "        self.last_action = ''\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Agent:- move: ({self.x} , {self.y}) ~ move happened: {self.action_happened} ~ last action: {self.last_action}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3be30a8-05fd-412d-8907-fcc375e8ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MazeEnv(gym.Env):\n",
    "    \n",
    "    # method -1\n",
    "    '''\n",
    "    The init method intialize all the variables needed.\n",
    "    '''\n",
    "    def __init__(self, conf):\n",
    "        try:\n",
    "            \n",
    "            self.conf = conf\n",
    "            \n",
    "            # We have 4 actions, corresponding to \"right\", \"up\", \"left\", \"down\"\n",
    "            # It describes the numerical structure of the legitimate actions that can be applied to the environment.\n",
    "            self.action_space = spaces.Discrete(4)\n",
    "            \n",
    "            rows = self.conf['env']['rows']\n",
    "            cols = self.conf['env']['cols']\n",
    "            \n",
    "            # observation is the x, y coordinate of the grid - agent's current cell position\n",
    "            # for 4x4 maze, low pos: [0, 0] high pos: [3, 3]\n",
    "            low = np.array([0, 0], dtype=np.int64)\n",
    "            high = np.array([rows-1, cols-1], dtype=np.int64)\n",
    "            self.observation_space = spaces.Box(low, high, shape=(2,), dtype=np.int64)\n",
    "\n",
    "            \n",
    "            # generate environment\n",
    "            self.maze = np.zeros((rows, cols))\n",
    "\n",
    "            # generate dummy env for tracking agent's visited cels\n",
    "            self.visited = np.zeros((rows, cols))\n",
    "\n",
    "            # generate Agent, Agent will always start from (0,0) cell\n",
    "            self.agent = Agent(0, 0)\n",
    "            self._updt_agent_pos(self.agent)\n",
    "\n",
    "            # generate initial state of maze and agent\n",
    "            self._gen_init_state()\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    # method -2\n",
    "    '''\n",
    "    The reset method will be called to initiate a new episode. \n",
    "    '''\n",
    "    def reset(self):\n",
    "        try:\n",
    "            self._gen_init_state()\n",
    "            observation = self._get_obs()\n",
    "            \n",
    "            return observation\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "     \n",
    "    # method -3\n",
    "    '''\n",
    "    The step method takes an action as an input and applies it to the environment, \n",
    "    which leads to the environment transitioning to a new state.\n",
    "    action: 'up', 'down', 'right', 'left'\n",
    "    '''\n",
    "    def step(self, action):\n",
    "        try:\n",
    "            # get the direction where agent should move\n",
    "            dir_num, dir_pos = self._action_to_direction(action)\n",
    "\n",
    "            # Whether the episode has been terminated\n",
    "            terminated = False\n",
    "            # The reward that you can get from the environment after executing the action \n",
    "            # that was given as the input to the step function.\n",
    "            reward = 0\n",
    "\n",
    "            # agent's new position\n",
    "            new_x = self.agent.x + dir_pos[0]\n",
    "            new_y = self.agent.y + dir_pos[1]\n",
    "\n",
    "            if not self._chk_pos_validity(new_x, new_y):\n",
    "                reward = -1 \n",
    "                self.agent.action_happened.add(action)\n",
    "                if len(self.agent.action_happened) == 4: # agent can not move any more\n",
    "                    terminated = True   \n",
    "            else:\n",
    "                self._updt_agent_pos(Agent(new_x, new_y))\n",
    "                self.agent.action_happened = set()\n",
    "                \n",
    "                terminated = True if self._win() else False\n",
    "                reward = 1 if terminated else 0.001\n",
    "\n",
    "            \n",
    "            self.agent.last_action = dir_num\n",
    "            \n",
    "            # The observation of the state of the environment.\n",
    "            observation = self._get_obs()\n",
    "            \n",
    "            # This provides additional information depending on the environment.\n",
    "            info = self._get_info()\n",
    "            \n",
    "            return observation, reward, terminated, info\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "    \n",
    "    # method -4\n",
    "    '''\n",
    "    The render method is for rendering the environment\n",
    "    '''\n",
    "    def render(self):\n",
    "        try:\n",
    "            self._visualize()\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    # method -5\n",
    "    '''\n",
    "    The close method should close any open resources that were used by the environment.\n",
    "    '''\n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    # translates the environmentâ€™s state into an observation\n",
    "    def _get_obs(self):\n",
    "        try:\n",
    "            return np.array([self.agent.x, self.agent.y], dtype=np.int64)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    # auxiliary information\n",
    "    def _get_info(self):\n",
    "        try:\n",
    "            return {\"visited\": self.visited}\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    # updating agent position in maze\n",
    "    def _updt_agent_pos(self, agent):\n",
    "        try:\n",
    "            self.agent.x = agent.x\n",
    "            self.agent.y = agent.y\n",
    "\n",
    "            self.visited[self.agent.x, self.agent.y] = 1\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    # checking agent position is valid or not in maze\n",
    "    def _chk_pos_validity(self,  x, y):\n",
    "        try:\n",
    "            rows = self.maze.shape[0]\n",
    "            cols = self.maze.shape[1]\n",
    "\n",
    "            # agent can not visit out of bound, obstacles, already visited cells\n",
    "            if x<0 or y<0 or x>=rows or y>=cols or self.maze[x][y] == -1 or self.visited[x][y] == 1:\n",
    "                return False\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    # condition for wining the game\n",
    "    def _win(self):\n",
    "        try:\n",
    "            if self.maze[self.agent.x, self.agent.y] == 1: # agent reached last cell\n",
    "                return True     \n",
    "            return False\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    \n",
    "    # It is for initializing maze and agent position\n",
    "    def _gen_init_state(self):\n",
    "        try:\n",
    "            # target will be always at the last cell\n",
    "            self.maze[-1, -1] = 1\n",
    "\n",
    "            # placing obstacles in maze\n",
    "            self.maze[0, 1:3] = -1\n",
    "            self.maze[1, 2:] = -1\n",
    "            self.maze[2, 0] = -1\n",
    "            self.maze[3, 0:2] = -1\n",
    "\n",
    "            # replacing agent at (0, 0) cell\n",
    "            self._updt_agent_pos(Agent(0, 0))\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    # It is for visualizing the maze's current position\n",
    "    def _visualize(self):\n",
    "        try:\n",
    "            maze = self.maze.copy()\n",
    "            maze[self.agent.x, self.agent.y] = self.agent.val\n",
    "            print(self.agent)\n",
    "            print(maze)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "    # converting action to direction\n",
    "    def _action_to_direction(self, action_num):\n",
    "        try:\n",
    "            ACTION = [\"down\", \"right\", \"up\", \"left\"]\n",
    "            \n",
    "            \n",
    "            action = {\n",
    "                'down': np.array([1, 0]),\n",
    "                'right': np.array([0, 1]),\n",
    "                'up': np.array([-1, 0]),\n",
    "                'left': np.array([0, -1]),\n",
    "            }\n",
    "            \n",
    "            return ACTION[action_num], action[ACTION[action_num]]\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91e309b3-4306-418a-b14b-650e7fb103ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf():\n",
    "    try:\n",
    "        conf = {\n",
    "            'env':{\n",
    "                    'rows': 4,\n",
    "                    'cols': 4\n",
    "                }\n",
    "        }       \n",
    "        return conf\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3a3336f-4e5d-4c20-8db6-96d756c09380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_env(env):\n",
    "    try:\n",
    "        # checking using in-built method\n",
    "        check_env(env)\n",
    "        \n",
    "        # checking using manual check\n",
    "        test_episodes = 2\n",
    "\n",
    "        for episode in range(1, test_episodes+1):\n",
    "\n",
    "            obs, info = env.reset()\n",
    "            terminated = False\n",
    "            score = 0\n",
    "\n",
    "            while not terminated:\n",
    "                env.render()\n",
    "                action = env.action_space.sample()\n",
    "                obs, reward, terminated, info = env.step(action)\n",
    "                score += reward\n",
    "\n",
    "            env.render()\n",
    "            print(f\"after episode:- {episode}, score:- {score}\")\n",
    "\n",
    "        env.close()\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "750f1ca0-946c-493e-9723-83cd8c3b415e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent:- move: (0 , 0) ~ move happened: {2} ~ last action: up\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {2, 3} ~ last action: left\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {1, 2, 3} ~ last action: right\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {0, 1, 2, 3} ~ last action: down\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "after episode:- 1, score:- -3\n",
      "Agent:- move: (0 , 0) ~ move happened: {0, 1, 2, 3} ~ last action: down\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "Agent:- move: (0 , 0) ~ move happened: {0, 1, 2, 3} ~ last action: right\n",
      "[[ 6. -1. -1.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [-1.  0.  0.  0.]\n",
      " [-1. -1.  0.  1.]]\n",
      "after episode:- 2, score:- -1\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # get config\n",
    "        conf = get_conf()\n",
    "        \n",
    "        # Create the environment ~ MAZE\n",
    "        m = MazeEnv(conf)\n",
    "        \n",
    "        # checking whether environment is working or not\n",
    "        test_env(m) \n",
    "        \n",
    "        print(\"DONE\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df7779-5652-41c4-8f1c-47f11768cb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a17d90a-6df0-4b75-b9a2-314d6c888cac",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77820782-2dc8-42da-8380-5845dbea32d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# it will generate discrete value beween [0, 1, 2, 3]\n",
    "discrete_space = spaces.Discrete(4)\n",
    "discrete_space_sample = discrete_space.sample()\n",
    "print(discrete_space_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "754d4f88-3f20-4cf3-95fa-c13dc4808785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 2]\n"
     ]
    }
   ],
   "source": [
    "# it will generate grid value beween low and high\n",
    "box_space = spaces.Box(low = 0, high = 10, shape=(2,), dtype=int)\n",
    "box_space_sample = box_space.sample()\n",
    "print(box_space_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c40e1f22-4dbf-4cb3-b6b4-25fb7db5a9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, array([3, 4]))\n"
     ]
    }
   ],
   "source": [
    "# it will generate tuple\n",
    "tuple_space = spaces.Tuple((spaces.Discrete(4), spaces.Box(low = 0, high = 10, shape=(2,), dtype=int)))\n",
    "tuple_space_sample = tuple_space.sample()\n",
    "print(tuple_space_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25c214a6-f992-4f36-a977-a560921ca9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('agent', 0), ('target', array([5, 8]))])\n"
     ]
    }
   ],
   "source": [
    "# it will generate dictionary\n",
    "dict_space = spaces.Dict(\n",
    "    {\n",
    "        \"agent\": spaces.Discrete(4),\n",
    "        \"target\": spaces.Box(low = 0, high = 10, shape=(2,), dtype=int),\n",
    "    }\n",
    ")\n",
    "dict_space_sample = dict_space.sample()\n",
    "print(dict_space_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee9e8ece-7757-4bbb-831a-5136212e5e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# it will generate multibinary\n",
    "multibin_space = spaces.MultiBinary(3)\n",
    "multibin_space_sample = multibin_space.sample()\n",
    "print(multibin_space_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e76af39-cc82-4159-bc78-3ec788909d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# it will generate multidiscrete\n",
    "multidiscrete_space = spaces.MultiDiscrete(4)\n",
    "multidiscrete_space_sample = multidiscrete_space.sample()\n",
    "print(multidiscrete_space_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4852c20c-cf84-4d11-981a-941558d2df4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
